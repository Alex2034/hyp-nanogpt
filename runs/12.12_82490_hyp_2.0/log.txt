====================================================================================================
import os
import sys
with open(sys.argv[0]) as f:
    code = f.read() # read the code of this file ASAP, for logging
import multiprocessing

import random
import datetime
import time
from torch.utils.tensorboard import SummaryWriter
import json

import glob
from dataclasses import dataclass
from transformers import PreTrainedTokenizerFast

import numpy as np
import math
import torch
from torch import nn
import torch.nn.functional as F
import torch.distributed as dist
import torch._inductor.config as config
from torch.nn.parallel import DistributedDataParallel as DDP

from lib.lorentz.manifold import CustomLorentz
from lib.geoopt.optim import RiemannianSGD

import argparse

torch.set_float32_matmul_precision('high')
os.environ["TOKENIZERS_PARALLELISM"] = "false"

# -----------------------------------------------------------------------------
# Muon optimizer

def zeropower_via_svd(G, steps=None):
    U, S, V = G.svd()
    return U @ V.T

@torch.compile
def zeropower_via_newtonschulz5(G, steps=10, eps=1e-7):
    """
    Newton-Schulz iteration to compute the zeroth power / orthogonalization of G. We opt to use a
    quintic iteration whose coefficients are selected to maximize the slope at zero. For the purpose
    of minimizing steps, it turns out to be empirically effective to keep increasing the slope at
    zero even beyond the point where the iteration no longer converges all the way to one everywhere
    on the interval. This iteration therefore does not produce UV^T but rather something like US'V^T
    where S' is diagonal with S_{ii}' \sim Uniform(0.5, 1.5), which turns out not to hurt model
    performance at all relative to UV^T, where USV^T = G is the SVD.
    """
    assert len(G.shape) == 2
    a, b, c = (3.4445, -4.7750,  2.0315)
    X = G.bfloat16()
    X /= (X.norm() + eps) # ensure top singular value <= 1
    if G.size(0) > G.size(1):
        X = X.T
    for _ in range(steps):
        A = X @ X.T
        B = A @ X
        X = a * X + b * B + c * A @ B
    if G.size(0) > G.size(1):
        X = X.T
    return X

zeropower_backends = dict(svd=zeropower_via_svd, newtonschulz5=zeropower_via_newtonschulz5)

class Muon(torch.optim.Optimizer):
    """
    Muon - MomentUm Orthogonalized by Newton-schulz

    Muon internally runs standard SGD-momentum, and then performs an orthogonalization post-
    processing step, in which each 2D parameter's update is replaced with the nearest orthogonal
    matrix. To efficiently orthogonalize each update, we use a Newton-Schulz iteration, which has
    the advantage that it can be stably run in bfloat16 on the GPU.

    Some warnings:
    - This optimizer assumes that all parameters passed in are 2D.
    - It should not be used for the embedding layer, the final fully connected layer, or any {0,1}-D
    parameters; those should all be optimized by a standard method (e.g., AdamW).
    - To use it with 4D convolutional filters, it works well to just flatten their last 3 dimensions.
    - We believe it is unlikely to work well for training with small batch size.
    - We believe it may not work well for finetuning pretrained models, but we haven't tested this.
    - We have not yet tried this optimizer for training scenarios larger than NanoGPT (124M).

    Arguments:
        lr: The learning rate used by the internal SGD.
        momentum: The momentum used by the internal SGD.
        nesterov: Whether to use Nesterov-style momentum in the internal SGD. (recommended)
        backend: The chosen backend for the orthogonalization step. (recommended: 'newtonschulz5')
        backend_steps: The number of iteration steps to use in the backend, if it is iterative.
    """
    def __init__(self, params, lr=0.02, momentum=0.95, nesterov=True,
                 backend='newtonschulz5', backend_steps=5):
        defaults = dict(lr=lr, momentum=momentum, nesterov=nesterov, backend=backend, backend_steps=backend_steps)
        super().__init__(params, defaults)

    def step(self):

        for group in self.param_groups:

            lr = group['lr']
            momentum = group['momentum']
            zeropower_backend = zeropower_backends[group['backend']]

            # generate weight updates in distributed fashion
            total_params = sum(p.numel() for p in group['params'])
            updates_flat = torch.zeros(total_params, device='cuda', dtype=torch.bfloat16)
            curr_idx = 0
            for i, p in enumerate(group['params']):
                # luckily this will perfectly distribute a transformer with multiple of 4 layers to 8 GPUs
                if i % int(os.environ['WORLD_SIZE']) == int(os.environ['RANK']):
                    g = p.grad
                    assert g is not None
                    state = self.state[p]
                    if 'momentum_buffer' not in state:
                        state['momentum_buffer'] = torch.zeros_like(g)
                    buf = state['momentum_buffer']
                    buf.mul_(momentum).add_(g)
                    if group['nesterov']:
                        g = g.add(buf, alpha=momentum)
                    g = zeropower_backend(g, steps=group['backend_steps'])
                    g *= max(1, g.size(0)/g.size(1))**0.5
                    updates_flat[curr_idx:curr_idx+p.numel()] = g.flatten()
                curr_idx += p.numel()

            # sync updates across devices. we are not memory-constrained so can do this simple deserialization
            dist.all_reduce(updates_flat, op=dist.ReduceOp.SUM)

            # deserialize and apply updates
            curr_idx = 0
            for p in group['params']:
                g = updates_flat[curr_idx:curr_idx+p.numel()].view_as(p.data).type_as(p.data)
                p.data.add_(g, alpha=-lr)
                curr_idx += p.numel()

# -----------------------------------------------------------------------------
# PyTorch nn.Module definitions for the GPT-2 model

class Rotary(torch.nn.Module):

    def __init__(self, dim, base=10000):
        super().__init__()
        self.inv_freq = 1.0 / (base ** (torch.arange(0, dim, 2).float() / dim))
        self.seq_len_cached = None
        self.cos_cached = None
        self.sin_cached = None

    def forward(self, x):
        seq_len = x.shape[1]
        if seq_len != self.seq_len_cached:
            self.seq_len_cached = seq_len
            t = torch.arange(seq_len, device=x.device).type_as(self.inv_freq)
            freqs = torch.outer(t, self.inv_freq).to(x.device)
            self.cos_cached = freqs.cos().bfloat16()
            self.sin_cached = freqs.sin().bfloat16()
        return self.cos_cached[None, :, None, :], self.sin_cached[None, :, None, :]

def apply_rotary_emb(x, cos, sin):
    assert x.ndim == 4 # multihead attention
    d = x.shape[3]//2
    x1 = x[..., :d]
    x2 = x[..., d:]
    y1 = x1 * cos + x2 * sin
    y2 = x1 * (-sin) + x2 * cos
    return torch.cat([y1, y2], 3).type_as(x)

class CausalSelfAttention(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.n_head = config.n_head
        self.n_embd = config.n_embd
        self.head_dim = self.n_embd // self.n_head
        assert self.n_embd % self.n_head == 0
        self.c_q = nn.Linear(self.n_embd, self.n_embd, bias=False)
        self.c_k = nn.Linear(self.n_embd, self.n_embd, bias=False)
        self.c_v = nn.Linear(self.n_embd, self.n_embd, bias=False)
        # output projection
        self.c_proj = nn.Linear(self.n_embd, self.n_embd, bias=False)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977
        self.rotary = Rotary(self.head_dim)

    def forward(self, x):
        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)
        q = self.c_q(x).view(B, T, self.n_head, self.head_dim)
        k = self.c_k(x).view(B, T, self.n_head, self.head_dim)
        v = self.c_v(x).view(B, T, self.n_head, self.head_dim)
        cos, sin = self.rotary(q)
        q, k = F.rms_norm(q, (q.size(-1),)), F.rms_norm(k, (k.size(-1),)) # QK norm suggested by @Grad62304977
        q, k = apply_rotary_emb(q, cos, sin), apply_rotary_emb(k, cos, sin)
        y = F.scaled_dot_product_attention(q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2), is_causal=True)
        y = y.transpose(1, 2).contiguous().view_as(x) # re-assemble all head outputs side by side
        y = self.c_proj(y)
        return y

class MLP(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd, bias=False)
        self.c_proj  = nn.Linear(4 * config.n_embd, config.n_embd, bias=False)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977

    def forward(self, x):
        x = self.c_fc(x)
        x = F.relu(x).square() # https://arxiv.org/abs/2109.08668v2; ~1-2% better than GELU; suggested by @SKYLINEZ007 and @Grad62304977
        x = self.c_proj(x)
        return x

class Block(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.attn = CausalSelfAttention(config)
        self.mlp = MLP(config)

    def forward(self, x):
        x = x + self.attn(F.rms_norm(x, (x.size(-1),)))
        x = x + self.mlp(F.rms_norm(x, (x.size(-1),)))
        return x

class LorentzMLR(nn.Module):
    """ Multinomial logistic regression (MLR) in the Lorentz model
    """
    def __init__(
            self, 
            manifold: CustomLorentz, 
            num_features: int, 
            num_classes: int
        ):
        super(LorentzMLR, self).__init__()

        self.manifold = manifold

        self.a = torch.nn.Parameter(torch.zeros(num_classes,))
        self.z = torch.nn.Parameter(F.pad(torch.zeros(num_classes, num_features-2), pad=(1,0), value=1)) # z should not be (0,0)

        self.init_weights()

    def forward(self, x):
        # x: (B, T, num_features)

        # Hyperplane parameters
        sqrt_mK = 1 / self.manifold.k.sqrt()  # scalar
        norm_z = torch.norm(self.z, dim=-1)  # (num_classes,)
        w_t = torch.sinh(sqrt_mK * self.a) * norm_z  # (num_classes,)
        w_s = torch.cosh(sqrt_mK * self.a).unsqueeze(-1) * self.z  # (num_classes, num_features -1)

        beta = torch.sqrt(-w_t**2 + torch.norm(w_s, dim=-1)**2)  # (num_classes,)

        x0 = x.narrow(-1, 0, 1)  # (B, T, 1)
        x_rest = x.narrow(-1, 1, x.shape[-1]-1)  # (B, T, num_features -1)
        inner_prod = torch.matmul(x_rest, self.z.T)  # (B, T, num_classes)
        alpha = -x0 * w_t.view(1, 1, -1) + torch.cosh(sqrt_mK * self.a).view(1, 1, -1) * inner_prod  # (B, T, num_classes)
        sqrt_mK_alpha_over_beta = sqrt_mK * alpha / beta.view(1, 1, -1)
        d = self.manifold.k.sqrt() * torch.abs(torch.asinh(sqrt_mK_alpha_over_beta))  # (B, T, num_classes)

        logits = torch.sign(alpha) * beta.view(1, 1, -1) * d  # (B, T, num_classes)

        return logits

    def init_weights(self):
        stdv = 1. / math.sqrt(self.z.size(1))
        nn.init.uniform_(self.z, -stdv, stdv)
        nn.init.uniform_(self.a, -stdv, stdv)

# -----------------------------------------------------------------------------
# The main GPT-2 model

@dataclass
class GPTConfig:
    vocab_size : int = 50304
    n_layer : int = 12
    n_head : int = 6 # head dim 128 suggested by @Grad62304977
    n_embd : int = 784
    lm_head : str = 'euc'
    curvature : float = 1.0

class GPT(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.config = config

        self.transformer = nn.ModuleDict(dict(
            wte = nn.Embedding(config.vocab_size, config.n_embd),
            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),
        ))

        if config.lm_head == 'euc':
            self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)
            self.lm_head.weight.data.zero_()

        elif config.lm_head == 'hyp':
            self.manifold = CustomLorentz(k=torch.tensor([config.curvature]))
            self.lm_head = LorentzMLR(
                manifold=self.manifold,
                num_features=config.n_embd,
                num_classes=config.vocab_size
            )
        else:
            raise ValueError("Invalid lm_head, choose 'euc'/'hyp'.")

    def forward(self, idx, targets=None, return_logits=True):

        # forward the GPT model itself
        x = self.transformer.wte(idx) # token embeddings of shape (b, t, n_embd)
        x = F.rms_norm(x, (x.size(-1),))
        for block in self.transformer.h:
            x = block(x)
        x = F.rms_norm(x, (x.size(-1),))

        if targets is not None:
            # if we are given some desired targets also calculate the loss
            logits = self.lm_head(x)
            logits = logits.float() # use tf32/fp32 for logits
            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)
        else:
            # inference-time mini-optimization: only forward the lm_head on the very last position
            logits = self.lm_head(x[:, [-1], :]) # note: using list [-1] to preserve the time dim
            logits = logits.float() # use tf32/fp32 for logits
            loss = None

        # there are performance reasons why not returning logits is prudent, if not needed
        if not return_logits:
            logits = None

        return logits, loss

# -----------------------------------------------------------------------------
# Our own simple Distributed Data Loader

def _peek_data_shard(filename):
    # only reads the header, returns header data
    with open(filename, "rb") as f:
        # first read the header, which is 256 int32 integers (4 bytes each)
        header = np.frombuffer(f.read(256*4), dtype=np.int32)
    if header[0] != 20240520:
        print("ERROR: magic number mismatch in the data .bin file!")
        print("---> HINT: Are you passing in a correct file with --input_bin?")
        print("---> HINT: Dataset encoding changed recently, re-run data prepro or refer again to README")
        print("---> HINT: For example re-run: `python dev/data/tinyshakespeare.py`, then re-try")
        exit(1)
    assert header[1] == 1, "unsupported version"
    ntok = header[2] # number of tokens (claimed)
    return ntok # for now just return the number of tokens

def _load_data_shard(filename):
    with open(filename, "rb") as f:
        # first read the header, which is 256 int32 integers (4 bytes each)
        header = np.frombuffer(f.read(256*4), dtype=np.int32)
        assert header[0] == 20240520, "magic number mismatch in the data .bin file"
        assert header[1] == 1, "unsupported version"
        ntok = header[2] # number of tokens (claimed)
        # the rest of it are tokens, stored as uint16
        tokens = np.frombuffer(f.read(), dtype=np.uint16)
    assert len(tokens) == ntok, "number of tokens read does not match header?"
    return tokens

class DistributedDataLoader:
    def __init__(self, filename_pattern, B, T, process_rank, num_processes):
        self.process_rank = process_rank
        self.num_processes = num_processes
        self.B = B
        self.T = T

        # glob files that match the pattern
        self.files = sorted(glob.glob(filename_pattern))
        assert len(self.files) > 0, f"did not find any files that match the pattern {filename_pattern}"

        # load and validate all data shards, count number of tokens in total
        ntok_total = 0
        for fname in self.files:
            shard_ntok = _peek_data_shard(fname)
            assert shard_ntok >= num_processes * B * T + 1
            ntok_total += int(shard_ntok)
        self.ntok_total = ntok_total

        # kick things off
        self.reset()

    def reset(self):
        self.current_shard = 0
        self.current_position = self.process_rank * self.B * self.T
        self.tokens = _load_data_shard(self.files[self.current_shard])

    def advance(self): # advance to next data shard
        self.current_shard = (self.current_shard + 1) % len(self.files)
        self.current_position = self.process_rank * self.B * self.T
        self.tokens = _load_data_shard(self.files[self.current_shard])

    def next_batch(self):
        B = self.B
        T = self.T
        buf = self.tokens[self.current_position : self.current_position+B*T+1]
        buf = torch.tensor(buf.astype(np.int32), dtype=torch.long)
        x = (buf[:-1]).view(B, T) # inputs
        y = (buf[1:]).view(B, T) # targets
        # advance current position and load next shard if necessary
        self.current_position += B * T * self.num_processes
        if self.current_position + (B * T * self.num_processes + 1) > len(self.tokens):
            self.advance()
        return x.cuda(), y.cuda()

def generate_text(model, context, max_length=200, temperature=1.0, top_k=50):
    model.eval()
    generated = context.clone()
    for _ in range(max_length):
        with torch.no_grad():
            logits, _ = model(generated, return_logits=True)
            logits = logits[:, -1, :] / temperature
            if top_k > 0:
                values, indices = torch.topk(logits, top_k)
                logits[logits < values[:, [-1]]] = -float('Inf')
            probs = F.softmax(logits, dim=-1)
            next_token = torch.multinomial(probs, num_samples=1)
            generated = torch.cat((generated, next_token), dim=1)
    return generated

def encode_text(text):
    """Encodes a string into token IDs."""
    return tokenizer.encode(text, return_tensors="pt").to(device)

def decode_tokens(tokens):
    """Decodes token IDs into a readable string."""
    return tokenizer.decode(tokens.cpu().tolist(), skip_special_tokens=True)


# -----------------------------------------------------------------------------
# int main

@dataclass
class Hyperparameters:
    # data hyperparams
    # input_bin : str = 'data/fineweb10B/fineweb_train_*.bin' # input .bin to train on
    # input_val_bin : str = 'data/fineweb10B/fineweb_val_*.bin' # input .bin to eval validation loss on
    data_path : str = 'data/tinystories'
    input_bin : str = 'data/tinystories/train.bin' # input .bin to train on
    input_val_bin : str = 'data/tinystories/val.bin' # input .bin to eval validation loss on
    num_vocab : int = 1000
    # optimization hyperparams
    batch_size : int = 2*32 # batch size, in sequences, across all devices
    device_batch_size : int = 32 # batch size, in sequences, per device
    sequence_length : int = 1024 # sequence length, in tokens
    num_iterations : int = 20_000 # number of iterations to run (for FW 2.7B was 4578)
    warmup_iters : int = 100
    warmdown_iters : int = 100 # number of iterations of linear warmup/warmdown for triangular or trapezoidal schedule
    weight_decay : float = 0
    # evaluation and logging hyperparams
    generate_every : int = 5000
    train_loss_every : int = 100 
    val_loss_every : int = 500 # every how many steps to evaluate val loss? 0 for only at the end
    val_tokens : int = 6160384 # how many tokens of validation data? it's important to keep this fixed for consistent comparisons
    save_every : int = 0 # every how many steps to save the checkpoint? 0 for only at the end
    # model
    vocab_size : int = 1000
    n_layer : int = 12
    n_head : int = 6 # head dim 128 suggested by @Grad62304977
    n_embd : int = 384
    lm_head : str = 'hyp'
    curvature : float = 1.0


parser = argparse.ArgumentParser(description="Train GPT model with customizable parameters.")
parser.add_argument(
    "--curvature",
    type=float,
    default=1.0,
    help="Set the curvature for the Lorentz manifold (default: 1.0)"
)

args_from_cli = parser.parse_args()


args = Hyperparameters(curvature=args_from_cli.curvature)

tokenizer = PreTrainedTokenizerFast(
    tokenizer_file=os.path.join(args.data_path, "tinystories_tokenizer.json"),
    eos_token="<|endoftext|>",
    unk_token="[UNK]",
    pad_token="[PAD]"  # Optional, but can be useful
)

# set up DDP (distributed data parallel). torchrun sets this env variable
assert torch.cuda.is_available()
dist.init_process_group(backend='nccl')
ddp_rank = int(os.environ['RANK'])
ddp_local_rank = int(os.environ['LOCAL_RANK'])
ddp_world_size = int(os.environ['WORLD_SIZE'])
device = f'cuda:{ddp_local_rank}'
torch.cuda.set_device(device)
print(f"using device: {device}")
master_process = (ddp_rank == 0) # this process will do logging, checkpointing etc.

# convenience variables
B, T = args.device_batch_size, args.sequence_length
# calculate the number of steps to take in the val loop.
assert args.val_tokens % (B * T * ddp_world_size) == 0
val_steps = args.val_tokens // (B * T * ddp_world_size)
# calculate the steps of gradient accumulation required to attain the desired global batch size.
assert args.batch_size % (B * ddp_world_size) == 0
train_accumulation_steps = args.batch_size // (B * ddp_world_size)

# load tokens
train_loader = DistributedDataLoader(args.input_bin, B, T, ddp_rank, ddp_world_size)
val_loader = DistributedDataLoader(args.input_val_bin, B, T, ddp_rank, ddp_world_size)
if master_process:
    print(f"Training DataLoader: total number of tokens: {train_loader.ntok_total} across {len(train_loader.files)} files")
    print(f"Validation DataLoader: total number of tokens: {val_loader.ntok_total} across {len(val_loader.files)} files")
x, y = train_loader.next_batch()

# there are only 50257 unique GPT-2 tokens; we extend to nearest multiple of 128 for efficiency. suggested to me by @Grad62304977.
# this originates from Karpathy's experiments.
# num_vocab = 50304
model = GPT(GPTConfig(vocab_size=args.num_vocab, 
                      n_layer=args.n_layer, 
                      n_head=args.n_head,
                      n_embd=args.n_embd,
                      lm_head=args.lm_head,
                      curvature=args.curvature))
model = model.cuda()
if hasattr(config, "coordinate_descent_tuning"):
    config.coordinate_descent_tuning = True # suggested by @Chillee
model = torch.compile(model)
# here we wrap model into DDP container
model = DDP(model, device_ids=[ddp_local_rank])
raw_model = model.module # always contains the "raw" unwrapped model
ctx = torch.amp.autocast(device_type='cuda', dtype=torch.bfloat16)

# init the optimizer(s)
# optimizer1 = torch.optim.Adam([raw_model.transformer.wte.weight], lr=0.3,   betas=(0.9, 0.95), fused=True)
# optimizer2 = torch.optim.Adam([raw_model.lm_head.weight],         lr=0.003, betas=(0.9, 0.95), fused=True)
# optimizer3 = Muon(raw_model.transformer.h.parameters(),           lr=0.02,  momentum=0.95)
# optimizers = [optimizer1, optimizer2, optimizer3]
# Fix the `k` parameter 
for name, param in raw_model.named_parameters():
    if "manifold.k" in name:
        param.requires_grad = False
        
lm_head_params = [p for p in raw_model.lm_head.parameters() if p.requires_grad]

params = list(raw_model.transformer.h.parameters())
matrix_params = [p for p in params if p.ndim == 2]
wte_params = [raw_model.transformer.wte.weight]

optimizer_lm_head = RiemannianSGD(
    [{'params': lm_head_params}], lr=0.05, weight_decay=5e-4, momentum=0.9, nesterov=True, stabilize=1
)

optimizer_muon = Muon(matrix_params, lr=0.05, momentum=0.95)

optimizer_wte = torch.optim.Adam(wte_params, lr=0.6, betas=(0.8, 0.95), fused=True)

optimizers = [optimizer_lm_head, optimizer_muon, optimizer_wte]


# learning rate decay scheduler (linear warmup and warmdown)
def get_lr(it):
    assert it <= args.num_iterations
    # 1) linear warmup for warmup_iters steps
    if it < args.warmup_iters:
        return (it+1) / args.warmup_iters
    # 2) constant lr for a while
    elif it >= args.num_iterations - args.warmdown_iters:
        return (args.num_iterations - it) / args.warmdown_iters
    # 3) 
    else:
        decay_ratio = (it - args.warmup_iters) / (args.num_iterations - args.warmup_iters)
        assert 0 <= decay_ratio <= 1
        return 0.1**decay_ratio

schedulers = [torch.optim.lr_scheduler.LambdaLR(opt, get_lr) for opt in optimizers]

# begin logging
if master_process:

    funny_animals = [
        "kinkajou", "platypus", "wombat", "parrot",
        "axolotl", "lemur", "blobfish", "dingo",
        "whale", "quokka", "sloth", "capybara", "emu",
        "koala", "marmoset", "meerkat", "panda"
    ]
    prefix = random.choice(funny_animals)
    now = datetime.datetime.now()
    date_part = now.strftime('%d.%m')  
    seconds_since_midnight = int(time.time() % 86400)
    run_id = f"{prefix}_{date_part}_{seconds_since_midnight}"

    # Create log directory and file
    logdir = f'runs/{run_id}/'
    os.makedirs(logdir, exist_ok=True)
    os.makedirs(os.path.join(logdir, "tensorboard_logs"), exist_ok=True)

    print(f"Logs for this run will be stored in: {logdir}")

    print("Writing logs to: " + os.path.join(logdir, "tensorboard_logs"))
    writer = SummaryWriter(log_dir=os.path.join(logdir, "tensorboard_logs"))

    config_path = os.path.join(logdir, "config.json")
    with open(config_path, "w") as f:
        json.dump(vars(args), f, indent=4)

    def pretty_json(hp):
        json_hp = json.dumps(hp, indent=2)
        return "".join("\t" + line for line in json_hp.splitlines(True))
    
    writer.add_text("run_params", pretty_json(vars(args)))
    logfile = os.path.join(logdir, 'log.txt')
    # create the log file
    with open(logfile, "w") as f:
        # begin the log by printing this file (the Python code)
        f.write('='*100 + '\n')
        f.write(code)
        f.write('='*100 + '\n')
        # log information about the hardware/software environment this is running on
        # and print the full `nvidia-smi` to file
        f.write(f"Running pytorch {torch.version.__version__} compiled for CUDA {torch.version.cuda}\nnvidia-smi:\n")
        import subprocess
        result = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
        f.write(f'{result.stdout}\n')
        f.write('='*100 + '\n')

training_time_s = 0.0
# start the clock
torch.cuda.synchronize()
t0 = time.time()
total_t0 = time.time()
train_loss_accum = 0.0
train_loss_count = 0
# begin training
train_loader.reset()
for step in range(args.num_iterations + 1):
    last_step = (step == args.num_iterations)
    # This effectively ignores timing first 10 steps, which are slower for weird reasons.
    # Alternately, and slightly more correctly in terms of benchmarking, we could do 10
    # steps with dummy data first, and then re-initialize the model and reset the loader.
    if step == 10:
        training_time_s = 0.0
        t0 = time.time()
    timed_steps = float('nan') if step <= 11 else (step - 10) + 1 # <= 11 to avoid bug in val

    # once in a while evaluate the validation dataset
    if (last_step or (args.val_loss_every > 0 and step % args.val_loss_every == 0)):
        # stop the clock
        torch.cuda.synchronize()
        training_time_s += time.time() - t0
        # run validation batches
        model.eval()
        val_loader.reset()
        val_loss = 0.0
        for _ in range(val_steps):
            x_val, y_val = val_loader.next_batch()
            with ctx: # of course, we'd like to use no_grad() here too, but that creates a torch.compile error for some reason
                _, loss = model(x_val, y_val, return_logits=False)
                val_loss += loss.detach()
                del loss
        dist.all_reduce(val_loss, op=dist.ReduceOp.AVG)
        val_loss /= val_steps
        # log val loss to console and to logfile
        if master_process:
            print(f'step:{step}/{args.num_iterations} val_loss:{val_loss:.4f} train_time:{training_time_s:.2f}s step_avg:{1000*training_time_s/(timed_steps-1):.0f}ms')
            with open(logfile, "a") as f:
                f.write(f'step:{step}/{args.num_iterations} val_loss:{val_loss:.4f} train_time:{training_time_s:.2f}s step_avg:{1000*training_time_s/(timed_steps-1):.0f}ms\n')
            writer.add_scalar('Loss/Validation', val_loss.item(), step)
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.time()

    if master_process and (step % args.generate_every == 0 or last_step):
        # Use a fixed prompt or context for generation
        prompt = "Once upon a time"  # Customize as per your dataset
        context = encode_text(prompt)
        
        # Generate text
        generated_tokens = generate_text(raw_model, context, max_length=200, temperature=1.0, top_k=50)
        generated_text = decode_tokens(generated_tokens[0])
        
        # Log the generated text to TensorBoard
        writer.add_text(f"Generated_Text/Step_{step}", generated_text, step)
        
        # Optionally log to console for immediate feedback
        print(f"[Step {step}] Generated Text: {generated_text}")


    if master_process and (last_step or (args.save_every > 0 and step % args.save_every == 0)):
        # stop the clock
        torch.cuda.synchronize()
        training_time_s += time.time() - t0
        # save the state of the training process
        log = dict(step=step, code=code, model=raw_model.state_dict(), optimizers=[opt.state_dict() for opt in optimizers])
        torch.save(log, 'ckpts/%s_state_step%06d.pt' % (run_id, step))
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.time()

    # bit confusing: we want to make sure to eval on 0th iteration
    # but also after the very last iteration. so we loop for step <= num_iterations
    # instead of just < num_iterations (one extra due to <=), only to do
    # the validation/sampling one last time, and then we break right here as we're done.
    if last_step:
        break

    # --------------- TRAINING SECTION BEGIN -----------------
    model.train()
    for i in range(1, train_accumulation_steps+1):
        # forward pass
        with ctx:
            _, loss = model(x, y, return_logits=False)
            train_loss = loss.detach()
        # advance the dataset for the next batch
        x, y = train_loader.next_batch()
        # backward pass
        if i < train_accumulation_steps:
            with model.no_sync(): # there's no need to sync gradients every accumulation step
                loss.backward()
        else:
            loss.backward() # just sync on the last step
    for name, p in model.named_parameters():
        if p.grad is None:
            # print(f"WARNING: Parameter {name} has no gradient. Skipping.")
            continue
        p.grad /= train_accumulation_steps
    # step the optimizers and schedulers
    for opt, sched in zip(optimizers, schedulers):
        opt.step()
        sched.step()
    # null the gradients
    model.zero_grad(set_to_none=True)
    train_loss_accum += train_loss.item()
    train_loss_count += 1
    # --------------- TRAINING SECTION END -------------------
    # everything that follows now is just diagnostics, prints, logging, etc.

    #dist.all_reduce(train_loss, op=dist.ReduceOp.AVG) # all-reducing the training loss would be more correct in terms of logging, but slower
    if master_process and (step+1) % args.train_loss_every == 0:
        avg_train_loss = train_loss_accum / train_loss_count
        elapsed_time = time.time() - total_t0
        approx_time = training_time_s + (time.time() - t0)
        avg_time_per_step = approx_time/timed_steps
        estimated_total_time = avg_time_per_step * args.num_iterations
        print(f"step:{step+1}/{args.num_iterations} avg_train_loss:{avg_train_loss:.4f} time:{elapsed_time:.0f}/{estimated_total_time:.0f}s step_avg:{1000*avg_time_per_step:.0f}ms")
        with open(logfile, "a") as f:
            f.write(f"step:{step+1}/{args.num_iterations} avg_train_loss:{avg_train_loss:.4f} time:{elapsed_time:.0f}s step_avg:{1000*avg_time_per_step:.0f}ms\n")
        writer.add_scalar('Loss/Train', avg_train_loss, step)
        train_loss_accum = 0.0
        train_loss_count = 0

if master_process:
    total_training_time = time.time() - total_t0
    print(f"Total training time: {total_training_time:.2f}s")
    with open(logfile, "a") as f:
        f.write(f"Total training time: {total_training_time:.2f}s\n")
    print(f"peak memory consumption: {torch.cuda.max_memory_allocated() // 1024 // 1024} MiB")

# -------------------------------------------------------------------------
# clean up nice
if master_process:
    writer.close()
dist.destroy_process_group()
====================================================================================================
Running pytorch 2.4.1+cu121 compiled for CUDA 12.1
nvidia-smi:
Thu Dec 12 22:54:50 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.154.05             Driver Version: 535.154.05   CUDA Version: 12.3     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA H100 80GB HBM3          On  | 00000000:19:00.0 Off |                    0 |
| N/A   46C    P0             497W / 700W |  61411MiB / 81559MiB |    100%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   1  NVIDIA H100 80GB HBM3          On  | 00000000:2D:00.0 Off |                    0 |
| N/A   50C    P0             489W / 700W |  61411MiB / 81559MiB |    100%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   2  NVIDIA H100 80GB HBM3          On  | 00000000:3F:00.0 Off |                    0 |
| N/A   31C    P0             117W / 700W |  12863MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   3  NVIDIA H100 80GB HBM3          On  | 00000000:66:00.0 Off |                    0 |
| N/A   29C    P0             113W / 700W |  61393MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   4  NVIDIA H100 80GB HBM3          On  | 00000000:9B:00.0 Off |                    0 |
| N/A   31C    P0             118W / 700W |   1659MiB / 81559MiB |      1%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   5  NVIDIA H100 80GB HBM3          On  | 00000000:AE:00.0 Off |                    0 |
| N/A   35C    P0             119W / 700W |   1659MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   6  NVIDIA H100 80GB HBM3          On  | 00000000:BF:00.0 Off |                    0 |
| N/A   28C    P0              73W / 700W |      0MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   7  NVIDIA H100 80GB HBM3          On  | 00000000:E4:00.0 Off |                    0 |
| N/A   27C    P0              73W / 700W |      0MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A   3106717      C   python3                                   61398MiB |
|    1   N/A  N/A   3108072      C   python3                                   61398MiB |
|    2   N/A  N/A   2984539      C   python                                    12854MiB |
|    3   N/A  N/A   3166257      C   ...miniconda3/envs/arudikov/bin/python    61380MiB |
|    4   N/A  N/A   3236702      C   ...niconda3/envs/fokin_HCNN/bin/python     1650MiB |
|    5   N/A  N/A   3236703      C   ...niconda3/envs/fokin_HCNN/bin/python     1650MiB |
+---------------------------------------------------------------------------------------+

====================================================================================================
step:0/20000 val_loss:7.0269 train_time:1.27s step_avg:nanms
step:100/20000 avg_train_loss:5.1009 time:226s step_avg:74ms
step:200/20000 avg_train_loss:3.3758 time:234s step_avg:74ms
step:300/20000 avg_train_loss:2.6656 time:241s step_avg:74ms
step:400/20000 avg_train_loss:2.3328 time:249s step_avg:74ms
step:500/20000 avg_train_loss:2.0819 time:256s step_avg:74ms
step:500/20000 val_loss:2.0210 train_time:36.21s step_avg:74ms
step:600/20000 avg_train_loss:1.9429 time:274s step_avg:74ms
step:700/20000 avg_train_loss:1.8397 time:282s step_avg:74ms
step:800/20000 avg_train_loss:1.7334 time:289s step_avg:74ms
step:900/20000 avg_train_loss:1.6833 time:296s step_avg:74ms
step:1000/20000 avg_train_loss:1.6401 time:304s step_avg:74ms
step:1000/20000 val_loss:1.6282 train_time:73.17s step_avg:74ms
step:1100/20000 avg_train_loss:1.5979 time:313s step_avg:74ms
step:1200/20000 avg_train_loss:1.5718 time:321s step_avg:74ms
step:1300/20000 avg_train_loss:1.5528 time:328s step_avg:74ms
step:1400/20000 avg_train_loss:1.4913 time:335s step_avg:74ms
step:1500/20000 avg_train_loss:1.5437 time:343s step_avg:74ms
step:1500/20000 val_loss:1.4910 train_time:110.12s step_avg:74ms
step:1600/20000 avg_train_loss:1.4798 time:352s step_avg:74ms
step:1700/20000 avg_train_loss:1.4780 time:359s step_avg:74ms
step:1800/20000 avg_train_loss:1.4535 time:367s step_avg:74ms
step:1900/20000 avg_train_loss:1.4358 time:374s step_avg:74ms
step:2000/20000 avg_train_loss:1.4317 time:382s step_avg:74ms
step:2000/20000 val_loss:1.4155 train_time:147.07s step_avg:74ms
step:2100/20000 avg_train_loss:1.4021 time:391s step_avg:74ms
step:2200/20000 avg_train_loss:1.3959 time:398s step_avg:74ms
step:2300/20000 avg_train_loss:1.3984 time:406s step_avg:74ms
step:2400/20000 avg_train_loss:1.3569 time:413s step_avg:74ms
step:2500/20000 avg_train_loss:1.3765 time:421s step_avg:74ms
step:2500/20000 val_loss:1.3696 train_time:184.01s step_avg:74ms
step:2600/20000 avg_train_loss:1.3523 time:430s step_avg:74ms
step:2700/20000 avg_train_loss:1.3450 time:437s step_avg:74ms
step:2800/20000 avg_train_loss:1.3346 time:445s step_avg:74ms
step:2900/20000 avg_train_loss:1.3425 time:452s step_avg:74ms
step:3000/20000 avg_train_loss:1.3423 time:460s step_avg:74ms
step:3000/20000 val_loss:1.3358 train_time:220.97s step_avg:74ms
step:3100/20000 avg_train_loss:1.2893 time:469s step_avg:74ms
step:3200/20000 avg_train_loss:1.3349 time:477s step_avg:74ms
step:3300/20000 avg_train_loss:1.3111 time:484s step_avg:74ms
step:3400/20000 avg_train_loss:1.3083 time:491s step_avg:74ms
step:3500/20000 avg_train_loss:1.2884 time:499s step_avg:74ms
step:3500/20000 val_loss:1.3082 train_time:257.93s step_avg:74ms
step:3600/20000 avg_train_loss:1.3135 time:508s step_avg:74ms
step:3700/20000 avg_train_loss:1.3435 time:516s step_avg:74ms
step:3800/20000 avg_train_loss:1.3294 time:523s step_avg:74ms
step:3900/20000 avg_train_loss:1.3178 time:530s step_avg:74ms
step:4000/20000 avg_train_loss:1.2730 time:538s step_avg:74ms
step:4000/20000 val_loss:1.2905 train_time:294.88s step_avg:74ms
step:4100/20000 avg_train_loss:1.2597 time:547s step_avg:74ms
step:4200/20000 avg_train_loss:1.2974 time:555s step_avg:74ms
step:4300/20000 avg_train_loss:1.2699 time:562s step_avg:74ms
step:4400/20000 avg_train_loss:1.2577 time:569s step_avg:74ms
step:4500/20000 avg_train_loss:1.2955 time:577s step_avg:74ms
step:4500/20000 val_loss:1.2717 train_time:331.83s step_avg:74ms
step:4600/20000 avg_train_loss:1.2900 time:586s step_avg:74ms
step:4700/20000 avg_train_loss:1.2705 time:594s step_avg:74ms
step:4800/20000 avg_train_loss:1.2602 time:601s step_avg:74ms
step:4900/20000 avg_train_loss:1.2772 time:608s step_avg:74ms
step:5000/20000 avg_train_loss:1.2753 time:616s step_avg:74ms
step:5000/20000 val_loss:1.2584 train_time:368.78s step_avg:74ms
step:5100/20000 avg_train_loss:1.2523 time:627s step_avg:74ms
step:5200/20000 avg_train_loss:1.2706 time:634s step_avg:74ms
step:5300/20000 avg_train_loss:1.2368 time:641s step_avg:74ms
step:5400/20000 avg_train_loss:1.2904 time:649s step_avg:74ms
step:5500/20000 avg_train_loss:1.2400 time:656s step_avg:74ms
step:5500/20000 val_loss:1.2485 train_time:407.15s step_avg:74ms
step:5600/20000 avg_train_loss:1.2296 time:666s step_avg:74ms
step:5700/20000 avg_train_loss:1.2022 time:673s step_avg:74ms
step:5800/20000 avg_train_loss:1.2324 time:680s step_avg:74ms
step:5900/20000 avg_train_loss:1.2551 time:688s step_avg:74ms
step:6000/20000 avg_train_loss:1.2249 time:695s step_avg:74ms
step:6000/20000 val_loss:1.2363 train_time:444.09s step_avg:74ms
step:6100/20000 avg_train_loss:1.2291 time:705s step_avg:74ms
step:6200/20000 avg_train_loss:1.2204 time:712s step_avg:74ms
step:6300/20000 avg_train_loss:1.2188 time:719s step_avg:74ms
step:6400/20000 avg_train_loss:1.2429 time:727s step_avg:74ms
step:6500/20000 avg_train_loss:1.2242 time:734s step_avg:74ms
step:6500/20000 val_loss:1.2264 train_time:481.02s step_avg:74ms
step:6600/20000 avg_train_loss:1.2446 time:744s step_avg:74ms
step:6700/20000 avg_train_loss:1.2189 time:751s step_avg:74ms
step:6800/20000 avg_train_loss:1.2432 time:758s step_avg:74ms
step:6900/20000 avg_train_loss:1.2154 time:766s step_avg:74ms
step:7000/20000 avg_train_loss:1.1970 time:773s step_avg:74ms
step:7000/20000 val_loss:1.2196 train_time:518.01s step_avg:74ms
step:7100/20000 avg_train_loss:1.2141 time:783s step_avg:74ms
step:7200/20000 avg_train_loss:1.2188 time:790s step_avg:74ms
step:7300/20000 avg_train_loss:1.2143 time:797s step_avg:74ms
step:7400/20000 avg_train_loss:1.2207 time:805s step_avg:74ms
step:7500/20000 avg_train_loss:1.2244 time:812s step_avg:74ms
step:7500/20000 val_loss:1.2114 train_time:554.99s step_avg:74ms
step:7600/20000 avg_train_loss:1.2210 time:822s step_avg:74ms
step:7700/20000 avg_train_loss:1.2320 time:829s step_avg:74ms
step:7800/20000 avg_train_loss:1.2311 time:836s step_avg:74ms
step:7900/20000 avg_train_loss:1.2175 time:844s step_avg:74ms
step:8000/20000 avg_train_loss:1.2616 time:851s step_avg:74ms
step:8000/20000 val_loss:1.2074 train_time:591.94s step_avg:74ms
step:8100/20000 avg_train_loss:1.2032 time:861s step_avg:74ms
step:8200/20000 avg_train_loss:1.2225 time:868s step_avg:74ms
step:8300/20000 avg_train_loss:1.1913 time:876s step_avg:74ms
step:8400/20000 avg_train_loss:1.2098 time:883s step_avg:74ms
step:8500/20000 avg_train_loss:1.2104 time:890s step_avg:74ms
step:8500/20000 val_loss:1.2002 train_time:629.08s step_avg:74ms
step:8600/20000 avg_train_loss:1.1841 time:900s step_avg:74ms
step:8700/20000 avg_train_loss:1.2007 time:907s step_avg:74ms
step:8800/20000 avg_train_loss:1.1948 time:915s step_avg:74ms
step:8900/20000 avg_train_loss:1.2019 time:922s step_avg:74ms
step:9000/20000 avg_train_loss:1.1885 time:929s step_avg:74ms
step:9000/20000 val_loss:1.1950 train_time:666.01s step_avg:74ms
step:9100/20000 avg_train_loss:1.2259 time:939s step_avg:74ms
step:9200/20000 avg_train_loss:1.1776 time:946s step_avg:74ms
step:9300/20000 avg_train_loss:1.1721 time:954s step_avg:74ms
step:9400/20000 avg_train_loss:1.1788 time:962s step_avg:74ms
step:9500/20000 avg_train_loss:1.1629 time:970s step_avg:74ms
step:9500/20000 val_loss:1.1878 train_time:704.22s step_avg:74ms
step:9600/20000 avg_train_loss:1.1979 time:979s step_avg:74ms
step:9700/20000 avg_train_loss:1.2302 time:986s step_avg:74ms
step:9800/20000 avg_train_loss:1.1764 time:994s step_avg:74ms
step:9900/20000 avg_train_loss:1.1823 time:1001s step_avg:74ms
step:10000/20000 avg_train_loss:1.1591 time:1009s step_avg:74ms
step:10000/20000 val_loss:1.1834 train_time:741.18s step_avg:74ms
step:10100/20000 avg_train_loss:1.1460 time:1019s step_avg:74ms
step:10200/20000 avg_train_loss:1.1537 time:1027s step_avg:74ms
step:10300/20000 avg_train_loss:1.1595 time:1034s step_avg:74ms
step:10400/20000 avg_train_loss:1.1628 time:1042s step_avg:74ms
step:10500/20000 avg_train_loss:1.1520 time:1049s step_avg:74ms
step:10500/20000 val_loss:1.1790 train_time:779.53s step_avg:74ms
step:10600/20000 avg_train_loss:1.2111 time:1058s step_avg:74ms
step:10700/20000 avg_train_loss:1.1309 time:1066s step_avg:74ms
step:10800/20000 avg_train_loss:1.1964 time:1073s step_avg:74ms
step:10900/20000 avg_train_loss:1.1883 time:1081s step_avg:74ms
step:11000/20000 avg_train_loss:1.1736 time:1088s step_avg:74ms
step:11000/20000 val_loss:1.1748 train_time:816.47s step_avg:74ms
step:11100/20000 avg_train_loss:1.1698 time:1097s step_avg:74ms
step:11200/20000 avg_train_loss:1.1916 time:1105s step_avg:74ms
step:11300/20000 avg_train_loss:1.1747 time:1112s step_avg:74ms
step:11400/20000 avg_train_loss:1.1767 time:1120s step_avg:74ms
step:11500/20000 avg_train_loss:1.1381 time:1127s step_avg:74ms
step:11500/20000 val_loss:1.1702 train_time:853.42s step_avg:74ms
step:11600/20000 avg_train_loss:1.1881 time:1136s step_avg:74ms
step:11700/20000 avg_train_loss:1.1441 time:1144s step_avg:74ms
step:11800/20000 avg_train_loss:1.1485 time:1151s step_avg:74ms
step:11900/20000 avg_train_loss:1.1512 time:1159s step_avg:74ms
step:12000/20000 avg_train_loss:1.1567 time:1166s step_avg:74ms
step:12000/20000 val_loss:1.1679 train_time:890.37s step_avg:74ms
step:12100/20000 avg_train_loss:1.1389 time:1175s step_avg:74ms
step:12200/20000 avg_train_loss:1.1621 time:1183s step_avg:74ms
step:12300/20000 avg_train_loss:1.1754 time:1190s step_avg:74ms
step:12400/20000 avg_train_loss:1.1192 time:1198s step_avg:74ms
step:12500/20000 avg_train_loss:1.1347 time:1205s step_avg:74ms
step:12500/20000 val_loss:1.1638 train_time:927.32s step_avg:74ms
step:12600/20000 avg_train_loss:1.1579 time:1214s step_avg:74ms
step:12700/20000 avg_train_loss:1.1369 time:1222s step_avg:74ms
step:12800/20000 avg_train_loss:1.1432 time:1229s step_avg:74ms
step:12900/20000 avg_train_loss:1.1434 time:1237s step_avg:74ms
step:13000/20000 avg_train_loss:1.1946 time:1244s step_avg:74ms
step:13000/20000 val_loss:1.1603 train_time:964.27s step_avg:74ms
step:13100/20000 avg_train_loss:1.1769 time:1253s step_avg:74ms
step:13200/20000 avg_train_loss:1.1969 time:1261s step_avg:74ms
step:13300/20000 avg_train_loss:1.1266 time:1268s step_avg:74ms
step:13400/20000 avg_train_loss:1.1384 time:1276s step_avg:74ms
step:13500/20000 avg_train_loss:1.1407 time:1283s step_avg:74ms
step:13500/20000 val_loss:1.1572 train_time:1001.22s step_avg:74ms
step:13600/20000 avg_train_loss:1.1449 time:1292s step_avg:74ms
step:13700/20000 avg_train_loss:1.1377 time:1300s step_avg:74ms
step:13800/20000 avg_train_loss:1.1486 time:1307s step_avg:74ms
step:13900/20000 avg_train_loss:1.1709 time:1315s step_avg:74ms
step:14000/20000 avg_train_loss:1.1332 time:1322s step_avg:74ms
step:14000/20000 val_loss:1.1544 train_time:1038.15s step_avg:74ms
step:14100/20000 avg_train_loss:1.1507 time:1331s step_avg:74ms
step:14200/20000 avg_train_loss:1.1467 time:1339s step_avg:74ms
step:14300/20000 avg_train_loss:1.1670 time:1346s step_avg:74ms
step:14400/20000 avg_train_loss:1.1403 time:1354s step_avg:74ms
step:14500/20000 avg_train_loss:1.1463 time:1361s step_avg:74ms
step:14500/20000 val_loss:1.1521 train_time:1075.09s step_avg:74ms
step:14600/20000 avg_train_loss:1.1353 time:1370s step_avg:74ms
step:14700/20000 avg_train_loss:1.1742 time:1378s step_avg:74ms
step:14800/20000 avg_train_loss:1.1408 time:1385s step_avg:74ms
step:14900/20000 avg_train_loss:1.1121 time:1393s step_avg:74ms
step:15000/20000 avg_train_loss:1.1188 time:1400s step_avg:74ms
step:15000/20000 val_loss:1.1503 train_time:1112.02s step_avg:74ms
step:15100/20000 avg_train_loss:1.1060 time:1411s step_avg:74ms
step:15200/20000 avg_train_loss:1.1410 time:1418s step_avg:74ms
step:15300/20000 avg_train_loss:1.1341 time:1426s step_avg:74ms
step:15400/20000 avg_train_loss:1.1311 time:1433s step_avg:74ms
step:15500/20000 avg_train_loss:1.1264 time:1440s step_avg:74ms
step:15500/20000 val_loss:1.1478 train_time:1150.36s step_avg:74ms
step:15600/20000 avg_train_loss:1.1395 time:1450s step_avg:74ms
step:15700/20000 avg_train_loss:1.1322 time:1457s step_avg:74ms
step:15800/20000 avg_train_loss:1.1327 time:1465s step_avg:74ms
step:15900/20000 avg_train_loss:1.1579 time:1472s step_avg:74ms
step:16000/20000 avg_train_loss:1.1332 time:1479s step_avg:74ms
step:16000/20000 val_loss:1.1456 train_time:1187.32s step_avg:74ms
step:16100/20000 avg_train_loss:1.1472 time:1489s step_avg:74ms
step:16200/20000 avg_train_loss:1.1379 time:1496s step_avg:74ms
step:16300/20000 avg_train_loss:1.1333 time:1504s step_avg:74ms
step:16400/20000 avg_train_loss:1.1108 time:1511s step_avg:74ms
step:16500/20000 avg_train_loss:1.1248 time:1518s step_avg:74ms
step:16500/20000 val_loss:1.1436 train_time:1224.28s step_avg:74ms
step:16600/20000 avg_train_loss:1.1325 time:1528s step_avg:74ms
step:16700/20000 avg_train_loss:1.1277 time:1535s step_avg:74ms
step:16800/20000 avg_train_loss:1.1494 time:1543s step_avg:74ms
step:16900/20000 avg_train_loss:1.1398 time:1550s step_avg:74ms
step:17000/20000 avg_train_loss:1.1561 time:1557s step_avg:74ms
step:17000/20000 val_loss:1.1421 train_time:1261.25s step_avg:74ms
step:17100/20000 avg_train_loss:1.1602 time:1567s step_avg:74ms
step:17200/20000 avg_train_loss:1.1396 time:1574s step_avg:74ms
step:17300/20000 avg_train_loss:1.1599 time:1582s step_avg:74ms
step:17400/20000 avg_train_loss:1.1673 time:1589s step_avg:74ms
step:17500/20000 avg_train_loss:1.1326 time:1596s step_avg:74ms
step:17500/20000 val_loss:1.1410 train_time:1298.24s step_avg:74ms
step:17600/20000 avg_train_loss:1.1082 time:1606s step_avg:74ms
step:17700/20000 avg_train_loss:1.1573 time:1613s step_avg:74ms
step:17800/20000 avg_train_loss:1.1358 time:1621s step_avg:74ms
step:17900/20000 avg_train_loss:1.1123 time:1628s step_avg:74ms
step:18000/20000 avg_train_loss:1.1241 time:1635s step_avg:74ms
step:18000/20000 val_loss:1.1394 train_time:1335.20s step_avg:74ms
step:18100/20000 avg_train_loss:1.1371 time:1645s step_avg:74ms
step:18200/20000 avg_train_loss:1.1118 time:1652s step_avg:74ms
step:18300/20000 avg_train_loss:1.1213 time:1660s step_avg:74ms
step:18400/20000 avg_train_loss:1.1465 time:1667s step_avg:74ms
step:18500/20000 avg_train_loss:1.1417 time:1674s step_avg:74ms
step:18500/20000 val_loss:1.1382 train_time:1372.14s step_avg:74ms
step:18600/20000 avg_train_loss:1.0985 time:1684s step_avg:74ms
step:18700/20000 avg_train_loss:1.1209 time:1693s step_avg:74ms
step:18800/20000 avg_train_loss:1.0897 time:1700s step_avg:74ms
step:18900/20000 avg_train_loss:1.1375 time:1707s step_avg:74ms
step:19000/20000 avg_train_loss:1.1544 time:1715s step_avg:74ms
step:19000/20000 val_loss:1.1365 train_time:1410.36s step_avg:74ms
step:19100/20000 avg_train_loss:1.1493 time:1724s step_avg:74ms
step:19200/20000 avg_train_loss:1.0930 time:1732s step_avg:74ms
step:19300/20000 avg_train_loss:1.1184 time:1739s step_avg:74ms
step:19400/20000 avg_train_loss:1.0845 time:1746s step_avg:74ms
step:19500/20000 avg_train_loss:1.1052 time:1754s step_avg:74ms
step:19500/20000 val_loss:1.1344 train_time:1447.32s step_avg:74ms
step:19600/20000 avg_train_loss:1.0794 time:1763s step_avg:74ms
step:19700/20000 avg_train_loss:1.1068 time:1771s step_avg:74ms
step:19800/20000 avg_train_loss:1.1035 time:1778s step_avg:74ms
step:19900/20000 avg_train_loss:1.1319 time:1785s step_avg:74ms
step:20000/20000 avg_train_loss:1.1430 time:1793s step_avg:74ms
step:20000/20000 val_loss:1.1603 train_time:1484.29s step_avg:74ms
Total training time: 1796.32s
