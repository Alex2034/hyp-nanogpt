====================================================================================================
import os
import sys
with open(sys.argv[0]) as f:
    code = f.read() # read the code of this file ASAP, for logging
import multiprocessing

import random
import datetime
import time
from torch.utils.tensorboard import SummaryWriter
import json

import glob
from dataclasses import dataclass
from transformers import PreTrainedTokenizerFast

import numpy as np
import math
import torch
from torch import nn
import torch.nn.functional as F
import torch.distributed as dist
import torch._inductor.config as config
from torch.nn.parallel import DistributedDataParallel as DDP

from lib.lorentz.manifold import CustomLorentz
from lib.geoopt.optim import RiemannianSGD

import argparse

torch.set_float32_matmul_precision('high')
os.environ["TOKENIZERS_PARALLELISM"] = "false"

# -----------------------------------------------------------------------------
# Muon optimizer

def zeropower_via_svd(G, steps=None):
    U, S, V = G.svd()
    return U @ V.T

@torch.compile
def zeropower_via_newtonschulz5(G, steps=10, eps=1e-7):
    """
    Newton-Schulz iteration to compute the zeroth power / orthogonalization of G. We opt to use a
    quintic iteration whose coefficients are selected to maximize the slope at zero. For the purpose
    of minimizing steps, it turns out to be empirically effective to keep increasing the slope at
    zero even beyond the point where the iteration no longer converges all the way to one everywhere
    on the interval. This iteration therefore does not produce UV^T but rather something like US'V^T
    where S' is diagonal with S_{ii}' \sim Uniform(0.5, 1.5), which turns out not to hurt model
    performance at all relative to UV^T, where USV^T = G is the SVD.
    """
    assert len(G.shape) == 2
    a, b, c = (3.4445, -4.7750,  2.0315)
    X = G.bfloat16()
    X /= (X.norm() + eps) # ensure top singular value <= 1
    if G.size(0) > G.size(1):
        X = X.T
    for _ in range(steps):
        A = X @ X.T
        B = A @ X
        X = a * X + b * B + c * A @ B
    if G.size(0) > G.size(1):
        X = X.T
    return X

zeropower_backends = dict(svd=zeropower_via_svd, newtonschulz5=zeropower_via_newtonschulz5)

class Muon(torch.optim.Optimizer):
    """
    Muon - MomentUm Orthogonalized by Newton-schulz

    Muon internally runs standard SGD-momentum, and then performs an orthogonalization post-
    processing step, in which each 2D parameter's update is replaced with the nearest orthogonal
    matrix. To efficiently orthogonalize each update, we use a Newton-Schulz iteration, which has
    the advantage that it can be stably run in bfloat16 on the GPU.

    Some warnings:
    - This optimizer assumes that all parameters passed in are 2D.
    - It should not be used for the embedding layer, the final fully connected layer, or any {0,1}-D
    parameters; those should all be optimized by a standard method (e.g., AdamW).
    - To use it with 4D convolutional filters, it works well to just flatten their last 3 dimensions.
    - We believe it is unlikely to work well for training with small batch size.
    - We believe it may not work well for finetuning pretrained models, but we haven't tested this.
    - We have not yet tried this optimizer for training scenarios larger than NanoGPT (124M).

    Arguments:
        lr: The learning rate used by the internal SGD.
        momentum: The momentum used by the internal SGD.
        nesterov: Whether to use Nesterov-style momentum in the internal SGD. (recommended)
        backend: The chosen backend for the orthogonalization step. (recommended: 'newtonschulz5')
        backend_steps: The number of iteration steps to use in the backend, if it is iterative.
    """
    def __init__(self, params, lr=0.02, momentum=0.95, nesterov=True,
                 backend='newtonschulz5', backend_steps=5):
        defaults = dict(lr=lr, momentum=momentum, nesterov=nesterov, backend=backend, backend_steps=backend_steps)
        super().__init__(params, defaults)

    def step(self):

        for group in self.param_groups:

            lr = group['lr']
            momentum = group['momentum']
            zeropower_backend = zeropower_backends[group['backend']]

            # generate weight updates in distributed fashion
            total_params = sum(p.numel() for p in group['params'])
            updates_flat = torch.zeros(total_params, device='cuda', dtype=torch.bfloat16)
            curr_idx = 0
            for i, p in enumerate(group['params']):
                # luckily this will perfectly distribute a transformer with multiple of 4 layers to 8 GPUs
                if i % int(os.environ['WORLD_SIZE']) == int(os.environ['RANK']):
                    g = p.grad
                    assert g is not None
                    state = self.state[p]
                    if 'momentum_buffer' not in state:
                        state['momentum_buffer'] = torch.zeros_like(g)
                    buf = state['momentum_buffer']
                    buf.mul_(momentum).add_(g)
                    if group['nesterov']:
                        g = g.add(buf, alpha=momentum)
                    g = zeropower_backend(g, steps=group['backend_steps'])
                    g *= max(1, g.size(0)/g.size(1))**0.5
                    updates_flat[curr_idx:curr_idx+p.numel()] = g.flatten()
                curr_idx += p.numel()

            # sync updates across devices. we are not memory-constrained so can do this simple deserialization
            dist.all_reduce(updates_flat, op=dist.ReduceOp.SUM)

            # deserialize and apply updates
            curr_idx = 0
            for p in group['params']:
                g = updates_flat[curr_idx:curr_idx+p.numel()].view_as(p.data).type_as(p.data)
                p.data.add_(g, alpha=-lr)
                curr_idx += p.numel()

# -----------------------------------------------------------------------------
# PyTorch nn.Module definitions for the GPT-2 model

class Rotary(torch.nn.Module):

    def __init__(self, dim, base=10000):
        super().__init__()
        self.inv_freq = 1.0 / (base ** (torch.arange(0, dim, 2).float() / dim))
        self.seq_len_cached = None
        self.cos_cached = None
        self.sin_cached = None

    def forward(self, x):
        seq_len = x.shape[1]
        if seq_len != self.seq_len_cached:
            self.seq_len_cached = seq_len
            t = torch.arange(seq_len, device=x.device).type_as(self.inv_freq)
            freqs = torch.outer(t, self.inv_freq).to(x.device)
            self.cos_cached = freqs.cos().bfloat16()
            self.sin_cached = freqs.sin().bfloat16()
        return self.cos_cached[None, :, None, :], self.sin_cached[None, :, None, :]

def apply_rotary_emb(x, cos, sin):
    assert x.ndim == 4 # multihead attention
    d = x.shape[3]//2
    x1 = x[..., :d]
    x2 = x[..., d:]
    y1 = x1 * cos + x2 * sin
    y2 = x1 * (-sin) + x2 * cos
    return torch.cat([y1, y2], 3).type_as(x)

class CausalSelfAttention(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.n_head = config.n_head
        self.n_embd = config.n_embd
        self.head_dim = self.n_embd // self.n_head
        assert self.n_embd % self.n_head == 0
        self.c_q = nn.Linear(self.n_embd, self.n_embd, bias=False)
        self.c_k = nn.Linear(self.n_embd, self.n_embd, bias=False)
        self.c_v = nn.Linear(self.n_embd, self.n_embd, bias=False)
        # output projection
        self.c_proj = nn.Linear(self.n_embd, self.n_embd, bias=False)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977
        self.rotary = Rotary(self.head_dim)

    def forward(self, x):
        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)
        q = self.c_q(x).view(B, T, self.n_head, self.head_dim)
        k = self.c_k(x).view(B, T, self.n_head, self.head_dim)
        v = self.c_v(x).view(B, T, self.n_head, self.head_dim)
        cos, sin = self.rotary(q)
        q, k = F.rms_norm(q, (q.size(-1),)), F.rms_norm(k, (k.size(-1),)) # QK norm suggested by @Grad62304977
        q, k = apply_rotary_emb(q, cos, sin), apply_rotary_emb(k, cos, sin)
        y = F.scaled_dot_product_attention(q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2), is_causal=True)
        y = y.transpose(1, 2).contiguous().view_as(x) # re-assemble all head outputs side by side
        y = self.c_proj(y)
        return y

class MLP(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd, bias=False)
        self.c_proj  = nn.Linear(4 * config.n_embd, config.n_embd, bias=False)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977

    def forward(self, x):
        x = self.c_fc(x)
        x = F.relu(x).square() # https://arxiv.org/abs/2109.08668v2; ~1-2% better than GELU; suggested by @SKYLINEZ007 and @Grad62304977
        x = self.c_proj(x)
        return x

class Block(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.attn = CausalSelfAttention(config)
        self.mlp = MLP(config)

    def forward(self, x):
        x = x + self.attn(F.rms_norm(x, (x.size(-1),)))
        x = x + self.mlp(F.rms_norm(x, (x.size(-1),)))
        return x

class LorentzMLR(nn.Module):
    """ Multinomial logistic regression (MLR) in the Lorentz model
    """
    def __init__(
            self, 
            manifold: CustomLorentz, 
            num_features: int, 
            num_classes: int
        ):
        super(LorentzMLR, self).__init__()

        self.manifold = manifold

        self.a = torch.nn.Parameter(torch.zeros(num_classes,))
        self.z = torch.nn.Parameter(F.pad(torch.zeros(num_classes, num_features-2), pad=(1,0), value=1)) # z should not be (0,0)

        self.init_weights()

    def forward(self, x):
        # x: (B, T, num_features)

        # Hyperplane parameters
        sqrt_mK = 1 / self.manifold.k.sqrt()  # scalar
        norm_z = torch.norm(self.z, dim=-1)  # (num_classes,)
        w_t = torch.sinh(sqrt_mK * self.a) * norm_z  # (num_classes,)
        w_s = torch.cosh(sqrt_mK * self.a).unsqueeze(-1) * self.z  # (num_classes, num_features -1)

        beta = torch.sqrt(-w_t**2 + torch.norm(w_s, dim=-1)**2)  # (num_classes,)

        x0 = x.narrow(-1, 0, 1)  # (B, T, 1)
        x_rest = x.narrow(-1, 1, x.shape[-1]-1)  # (B, T, num_features -1)
        inner_prod = torch.matmul(x_rest, self.z.T)  # (B, T, num_classes)
        alpha = -x0 * w_t.view(1, 1, -1) + torch.cosh(sqrt_mK * self.a).view(1, 1, -1) * inner_prod  # (B, T, num_classes)
        sqrt_mK_alpha_over_beta = sqrt_mK * alpha / beta.view(1, 1, -1)
        d = self.manifold.k.sqrt() * torch.abs(torch.asinh(sqrt_mK_alpha_over_beta))  # (B, T, num_classes)

        logits = torch.sign(alpha) * beta.view(1, 1, -1) * d  # (B, T, num_classes)

        return logits

    def init_weights(self):
        stdv = 1. / math.sqrt(self.z.size(1))
        nn.init.uniform_(self.z, -stdv, stdv)
        nn.init.uniform_(self.a, -stdv, stdv)

# -----------------------------------------------------------------------------
# The main GPT-2 model

@dataclass
class GPTConfig:
    vocab_size : int = 50304
    n_layer : int = 12
    n_head : int = 6 # head dim 128 suggested by @Grad62304977
    n_embd : int = 784
    lm_head : str = 'euc'
    curvature : float = 1.0

class GPT(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.config = config

        self.transformer = nn.ModuleDict(dict(
            wte = nn.Embedding(config.vocab_size, config.n_embd),
            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),
        ))

        if config.lm_head == 'euc':
            self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)
            self.lm_head.weight.data.zero_()

        elif config.lm_head == 'hyp':
            self.manifold = CustomLorentz(k=torch.tensor([config.curvature]))
            self.lm_head = LorentzMLR(
                manifold=self.manifold,
                num_features=config.n_embd,
                num_classes=config.vocab_size
            )
        else:
            raise ValueError("Invalid lm_head, choose 'euc'/'hyp'.")

    def forward(self, idx, targets=None, return_logits=True):

        # forward the GPT model itself
        x = self.transformer.wte(idx) # token embeddings of shape (b, t, n_embd)
        x = F.rms_norm(x, (x.size(-1),))
        for block in self.transformer.h:
            x = block(x)
        x = F.rms_norm(x, (x.size(-1),))

        if targets is not None:
            # if we are given some desired targets also calculate the loss
            logits = self.lm_head(x)
            logits = logits.float() # use tf32/fp32 for logits
            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)
        else:
            # inference-time mini-optimization: only forward the lm_head on the very last position
            logits = self.lm_head(x[:, [-1], :]) # note: using list [-1] to preserve the time dim
            logits = logits.float() # use tf32/fp32 for logits
            loss = None

        # there are performance reasons why not returning logits is prudent, if not needed
        if not return_logits:
            logits = None

        return logits, loss

# -----------------------------------------------------------------------------
# Our own simple Distributed Data Loader

def _peek_data_shard(filename):
    # only reads the header, returns header data
    with open(filename, "rb") as f:
        # first read the header, which is 256 int32 integers (4 bytes each)
        header = np.frombuffer(f.read(256*4), dtype=np.int32)
    if header[0] != 20240520:
        print("ERROR: magic number mismatch in the data .bin file!")
        print("---> HINT: Are you passing in a correct file with --input_bin?")
        print("---> HINT: Dataset encoding changed recently, re-run data prepro or refer again to README")
        print("---> HINT: For example re-run: `python dev/data/tinyshakespeare.py`, then re-try")
        exit(1)
    assert header[1] == 1, "unsupported version"
    ntok = header[2] # number of tokens (claimed)
    return ntok # for now just return the number of tokens

def _load_data_shard(filename):
    with open(filename, "rb") as f:
        # first read the header, which is 256 int32 integers (4 bytes each)
        header = np.frombuffer(f.read(256*4), dtype=np.int32)
        assert header[0] == 20240520, "magic number mismatch in the data .bin file"
        assert header[1] == 1, "unsupported version"
        ntok = header[2] # number of tokens (claimed)
        # the rest of it are tokens, stored as uint16
        tokens = np.frombuffer(f.read(), dtype=np.uint16)
    assert len(tokens) == ntok, "number of tokens read does not match header?"
    return tokens

class DistributedDataLoader:
    def __init__(self, filename_pattern, B, T, process_rank, num_processes):
        self.process_rank = process_rank
        self.num_processes = num_processes
        self.B = B
        self.T = T

        # glob files that match the pattern
        self.files = sorted(glob.glob(filename_pattern))
        assert len(self.files) > 0, f"did not find any files that match the pattern {filename_pattern}"

        # load and validate all data shards, count number of tokens in total
        ntok_total = 0
        for fname in self.files:
            shard_ntok = _peek_data_shard(fname)
            assert shard_ntok >= num_processes * B * T + 1
            ntok_total += int(shard_ntok)
        self.ntok_total = ntok_total

        # kick things off
        self.reset()

    def reset(self):
        self.current_shard = 0
        self.current_position = self.process_rank * self.B * self.T
        self.tokens = _load_data_shard(self.files[self.current_shard])

    def advance(self): # advance to next data shard
        self.current_shard = (self.current_shard + 1) % len(self.files)
        self.current_position = self.process_rank * self.B * self.T
        self.tokens = _load_data_shard(self.files[self.current_shard])

    def next_batch(self):
        B = self.B
        T = self.T
        buf = self.tokens[self.current_position : self.current_position+B*T+1]
        buf = torch.tensor(buf.astype(np.int32), dtype=torch.long)
        x = (buf[:-1]).view(B, T) # inputs
        y = (buf[1:]).view(B, T) # targets
        # advance current position and load next shard if necessary
        self.current_position += B * T * self.num_processes
        if self.current_position + (B * T * self.num_processes + 1) > len(self.tokens):
            self.advance()
        return x.cuda(), y.cuda()

def generate_text(model, context, max_length=200, temperature=1.0, top_k=50):
    model.eval()
    generated = context.clone()
    for _ in range(max_length):
        with torch.no_grad():
            logits, _ = model(generated, return_logits=True)
            logits = logits[:, -1, :] / temperature
            if top_k > 0:
                values, indices = torch.topk(logits, top_k)
                logits[logits < values[:, [-1]]] = -float('Inf')
            probs = F.softmax(logits, dim=-1)
            next_token = torch.multinomial(probs, num_samples=1)
            generated = torch.cat((generated, next_token), dim=1)
    return generated

def encode_text(text):
    """Encodes a string into token IDs."""
    return tokenizer.encode(text, return_tensors="pt").to(device)

def decode_tokens(tokens):
    """Decodes token IDs into a readable string."""
    return tokenizer.decode(tokens.cpu().tolist(), skip_special_tokens=True)


# -----------------------------------------------------------------------------
# int main

@dataclass
class Hyperparameters:
    # data hyperparams
    # input_bin : str = 'data/fineweb10B/fineweb_train_*.bin' # input .bin to train on
    # input_val_bin : str = 'data/fineweb10B/fineweb_val_*.bin' # input .bin to eval validation loss on
    data_path : str = 'data/tinystories'
    input_bin : str = 'data/tinystories/train.bin' # input .bin to train on
    input_val_bin : str = 'data/tinystories/val.bin' # input .bin to eval validation loss on
    num_vocab : int = 1000
    # optimization hyperparams
    batch_size : int = 64 # batch size, in sequences, across all devices
    device_batch_size : int = 64 # batch size, in sequences, per device
    sequence_length : int = 1024 # sequence length, in tokens
    num_iterations : int = 20_000 # number of iterations to run (for FW 2.7B was 4578)
    warmup_iters : int = 100
    warmdown_iters : int = 100 # number of iterations of linear warmup/warmdown for triangular or trapezoidal schedule
    weight_decay : float = 0
    # evaluation and logging hyperparams
    generate_every : int = 5000
    train_loss_every : int = 100 
    val_loss_every : int = 500 # every how many steps to evaluate val loss? 0 for only at the end
    val_tokens : int = 6160384 # how many tokens of validation data? it's important to keep this fixed for consistent comparisons
    save_every : int = 0 # every how many steps to save the checkpoint? 0 for only at the end
    # model
    vocab_size : int = 1000
    n_layer : int = 12
    n_head : int = 6 # head dim 128 suggested by @Grad62304977
    n_embd : int = 384
    lm_head : str = 'hyp'
    curvature : float = 1.0


parser = argparse.ArgumentParser(description="Train GPT model with customizable parameters.")
parser.add_argument(
    "--curvature",
    type=float,
    default=1.0,
    help="Set the curvature for the Lorentz manifold (default: 1.0)"
)

args_from_cli = parser.parse_args()


args = Hyperparameters(curvature=args_from_cli.curvature)

tokenizer = PreTrainedTokenizerFast(
    tokenizer_file=os.path.join(args.data_path, "tinystories_tokenizer.json"),
    eos_token="<|endoftext|>",
    unk_token="[UNK]",
    pad_token="[PAD]"  # Optional, but can be useful
)

# set up DDP (distributed data parallel). torchrun sets this env variable
assert torch.cuda.is_available()
dist.init_process_group(backend='nccl')
ddp_rank = int(os.environ['RANK'])
ddp_local_rank = int(os.environ['LOCAL_RANK'])
ddp_world_size = int(os.environ['WORLD_SIZE'])
device = f'cuda:{ddp_local_rank}'
torch.cuda.set_device(device)
print(f"using device: {device}")
master_process = (ddp_rank == 0) # this process will do logging, checkpointing etc.

# convenience variables
B, T = args.device_batch_size, args.sequence_length
# calculate the number of steps to take in the val loop.
assert args.val_tokens % (B * T * ddp_world_size) == 0
val_steps = args.val_tokens // (B * T * ddp_world_size)
# calculate the steps of gradient accumulation required to attain the desired global batch size.
assert args.batch_size % (B * ddp_world_size) == 0
train_accumulation_steps = args.batch_size // (B * ddp_world_size)

# load tokens
train_loader = DistributedDataLoader(args.input_bin, B, T, ddp_rank, ddp_world_size)
val_loader = DistributedDataLoader(args.input_val_bin, B, T, ddp_rank, ddp_world_size)
if master_process:
    print(f"Training DataLoader: total number of tokens: {train_loader.ntok_total} across {len(train_loader.files)} files")
    print(f"Validation DataLoader: total number of tokens: {val_loader.ntok_total} across {len(val_loader.files)} files")
x, y = train_loader.next_batch()

# there are only 50257 unique GPT-2 tokens; we extend to nearest multiple of 128 for efficiency. suggested to me by @Grad62304977.
# this originates from Karpathy's experiments.
# num_vocab = 50304
model = GPT(GPTConfig(vocab_size=args.num_vocab, 
                      n_layer=args.n_layer, 
                      n_head=args.n_head,
                      n_embd=args.n_embd,
                      lm_head=args.lm_head,
                      curvature=args.curvature))
model = model.cuda()
if hasattr(config, "coordinate_descent_tuning"):
    config.coordinate_descent_tuning = True # suggested by @Chillee
model = torch.compile(model)
# here we wrap model into DDP container
model = DDP(model, device_ids=[ddp_local_rank])
raw_model = model.module # always contains the "raw" unwrapped model
ctx = torch.amp.autocast(device_type='cuda', dtype=torch.bfloat16)

# init the optimizer(s)
# optimizer1 = torch.optim.Adam([raw_model.transformer.wte.weight], lr=0.3,   betas=(0.9, 0.95), fused=True)
# optimizer2 = torch.optim.Adam([raw_model.lm_head.weight],         lr=0.003, betas=(0.9, 0.95), fused=True)
# optimizer3 = Muon(raw_model.transformer.h.parameters(),           lr=0.02,  momentum=0.95)
# optimizers = [optimizer1, optimizer2, optimizer3]
# Fix the `k` parameter 
for name, param in raw_model.named_parameters():
    if "manifold.k" in name:
        param.requires_grad = False
        
lm_head_params = [p for p in raw_model.lm_head.parameters() if p.requires_grad]

params = list(raw_model.transformer.h.parameters())
matrix_params = [p for p in params if p.ndim == 2]
wte_params = [raw_model.transformer.wte.weight]

optimizer_lm_head = RiemannianSGD(
    [{'params': lm_head_params}], lr=0.05, weight_decay=5e-4, momentum=0.9, nesterov=True, stabilize=1
)

optimizer_muon = Muon(matrix_params, lr=0.05, momentum=0.95)

optimizer_wte = torch.optim.Adam(wte_params, lr=0.6, betas=(0.8, 0.95), fused=True)

optimizers = [optimizer_lm_head, optimizer_muon, optimizer_wte]


# learning rate decay scheduler (linear warmup and warmdown)
def get_lr(it):
    assert it <= args.num_iterations
    # 1) linear warmup for warmup_iters steps
    if it < args.warmup_iters:
        return (it+1) / args.warmup_iters
    # 2) constant lr for a while
    elif it >= args.num_iterations - args.warmdown_iters:
        return (args.num_iterations - it) / args.warmdown_iters
    # 3) 
    else:
        decay_ratio = (it - args.warmup_iters) / (args.num_iterations - args.warmup_iters)
        assert 0 <= decay_ratio <= 1
        return 0.1**decay_ratio

schedulers = [torch.optim.lr_scheduler.LambdaLR(opt, get_lr) for opt in optimizers]

# begin logging
if master_process:

    funny_animals = [
        "kinkajou", "platypus", "wombat", "parrot",
        "axolotl", "lemur", "blobfish", "dingo",
        "whale", "quokka", "sloth", "capybara", "emu",
        "koala", "marmoset", "meerkat", "panda"
    ]
    prefix = random.choice(funny_animals)
    now = datetime.datetime.now()
    date_part = now.strftime('%d.%m')  
    seconds_since_midnight = int(time.time() % 86400)
    run_id = f"{prefix}_{date_part}_{seconds_since_midnight}"

    # Create log directory and file
    logdir = f'runs/{run_id}/'
    os.makedirs(logdir, exist_ok=True)
    os.makedirs(os.path.join(logdir, "tensorboard_logs"), exist_ok=True)

    print(f"Logs for this run will be stored in: {logdir}")

    print("Writing logs to: " + os.path.join(logdir, "tensorboard_logs"))
    writer = SummaryWriter(log_dir=os.path.join(logdir, "tensorboard_logs"))

    config_path = os.path.join(logdir, "config.json")
    with open(config_path, "w") as f:
        json.dump(vars(args), f, indent=4)

    def pretty_json(hp):
        json_hp = json.dumps(hp, indent=2)
        return "".join("\t" + line for line in json_hp.splitlines(True))
    
    writer.add_text("run_params", pretty_json(vars(args)))
    logfile = os.path.join(logdir, 'log.txt')
    # create the log file
    with open(logfile, "w") as f:
        # begin the log by printing this file (the Python code)
        f.write('='*100 + '\n')
        f.write(code)
        f.write('='*100 + '\n')
        # log information about the hardware/software environment this is running on
        # and print the full `nvidia-smi` to file
        f.write(f"Running pytorch {torch.version.__version__} compiled for CUDA {torch.version.cuda}\nnvidia-smi:\n")
        import subprocess
        result = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
        f.write(f'{result.stdout}\n')
        f.write('='*100 + '\n')

training_time_s = 0.0
# start the clock
torch.cuda.synchronize()
t0 = time.time()
total_t0 = time.time()
train_loss_accum = 0.0
train_loss_count = 0
# begin training
train_loader.reset()
for step in range(args.num_iterations + 1):
    last_step = (step == args.num_iterations)
    # This effectively ignores timing first 10 steps, which are slower for weird reasons.
    # Alternately, and slightly more correctly in terms of benchmarking, we could do 10
    # steps with dummy data first, and then re-initialize the model and reset the loader.
    if step == 10:
        training_time_s = 0.0
        t0 = time.time()
    timed_steps = float('nan') if step <= 11 else (step - 10) + 1 # <= 11 to avoid bug in val

    # once in a while evaluate the validation dataset
    if (last_step or (args.val_loss_every > 0 and step % args.val_loss_every == 0)):
        # stop the clock
        torch.cuda.synchronize()
        training_time_s += time.time() - t0
        # run validation batches
        model.eval()
        val_loader.reset()
        val_loss = 0.0
        for _ in range(val_steps):
            x_val, y_val = val_loader.next_batch()
            with ctx: # of course, we'd like to use no_grad() here too, but that creates a torch.compile error for some reason
                _, loss = model(x_val, y_val, return_logits=False)
                val_loss += loss.detach()
                del loss
        dist.all_reduce(val_loss, op=dist.ReduceOp.AVG)
        val_loss /= val_steps
        # log val loss to console and to logfile
        if master_process:
            print(f'step:{step}/{args.num_iterations} val_loss:{val_loss:.4f} train_time:{training_time_s:.2f}s step_avg:{1000*training_time_s/(timed_steps-1):.0f}ms')
            with open(logfile, "a") as f:
                f.write(f'step:{step}/{args.num_iterations} val_loss:{val_loss:.4f} train_time:{training_time_s:.2f}s step_avg:{1000*training_time_s/(timed_steps-1):.0f}ms\n')
            writer.add_scalar('Loss/Validation', val_loss.item(), step)
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.time()

    if master_process and (step % args.generate_every == 0 or last_step):
        # Use a fixed prompt or context for generation
        prompt = "Once upon a time"  # Customize as per your dataset
        context = encode_text(prompt)
        
        # Generate text
        generated_tokens = generate_text(raw_model, context, max_length=200, temperature=1.0, top_k=50)
        generated_text = decode_tokens(generated_tokens[0])
        
        # Log the generated text to TensorBoard
        writer.add_text(f"Generated_Text/Step_{step}", generated_text, step)
        
        # Optionally log to console for immediate feedback
        print(f"[Step {step}] Generated Text: {generated_text}")


    if master_process and (last_step or (args.save_every > 0 and step % args.save_every == 0)):
        # stop the clock
        torch.cuda.synchronize()
        training_time_s += time.time() - t0
        # save the state of the training process
        log = dict(step=step, code=code, model=raw_model.state_dict(), optimizers=[opt.state_dict() for opt in optimizers])
        torch.save(log, 'ckpts/%s_state_step%06d.pt' % (run_id, step))
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.time()

    # bit confusing: we want to make sure to eval on 0th iteration
    # but also after the very last iteration. so we loop for step <= num_iterations
    # instead of just < num_iterations (one extra due to <=), only to do
    # the validation/sampling one last time, and then we break right here as we're done.
    if last_step:
        break

    # --------------- TRAINING SECTION BEGIN -----------------
    model.train()
    for i in range(1, train_accumulation_steps+1):
        # forward pass
        with ctx:
            _, loss = model(x, y, return_logits=False)
            train_loss = loss.detach()
        # advance the dataset for the next batch
        x, y = train_loader.next_batch()
        # backward pass
        if i < train_accumulation_steps:
            with model.no_sync(): # there's no need to sync gradients every accumulation step
                loss.backward()
        else:
            loss.backward() # just sync on the last step
    for name, p in model.named_parameters():
        if p.grad is None:
            # print(f"WARNING: Parameter {name} has no gradient. Skipping.")
            continue
        p.grad /= train_accumulation_steps
    # step the optimizers and schedulers
    for opt, sched in zip(optimizers, schedulers):
        opt.step()
        sched.step()
    # null the gradients
    model.zero_grad(set_to_none=True)
    train_loss_accum += train_loss.item()
    train_loss_count += 1
    # --------------- TRAINING SECTION END -------------------
    # everything that follows now is just diagnostics, prints, logging, etc.

    #dist.all_reduce(train_loss, op=dist.ReduceOp.AVG) # all-reducing the training loss would be more correct in terms of logging, but slower
    if master_process and (step+1) % args.train_loss_every == 0:
        avg_train_loss = train_loss_accum / train_loss_count
        elapsed_time = time.time() - total_t0
        approx_time = training_time_s + (time.time() - t0)
        avg_time_per_step = approx_time/timed_steps
        estimated_total_time = avg_time_per_step * args.num_iterations
        print(f"step:{step+1}/{args.num_iterations} avg_train_loss:{avg_train_loss:.4f} time:{elapsed_time:.0f}/{estimated_total_time:.0f}s step_avg:{1000*avg_time_per_step:.0f}ms")
        with open(logfile, "a") as f:
            f.write(f"step:{step+1}/{args.num_iterations} avg_train_loss:{avg_train_loss:.4f} time:{elapsed_time:.0f}s step_avg:{1000*avg_time_per_step:.0f}ms\n")
        writer.add_scalar('Loss/Train', avg_train_loss, step)
        train_loss_accum = 0.0
        train_loss_count = 0

if master_process:
    total_training_time = time.time() - total_t0
    print(f"Total training time: {total_training_time:.2f}s")
    with open(logfile, "a") as f:
        f.write(f"Total training time: {total_training_time:.2f}s\n")
    print(f"peak memory consumption: {torch.cuda.max_memory_allocated() // 1024 // 1024} MiB")

# -------------------------------------------------------------------------
# clean up nice
if master_process:
    writer.close()
dist.destroy_process_group()
====================================================================================================
Running pytorch 2.4.1+cu121 compiled for CUDA 12.1
nvidia-smi:
Sun Dec 15 00:52:19 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.154.05             Driver Version: 535.154.05   CUDA Version: 12.3     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA H100 80GB HBM3          On  | 00000000:19:00.0 Off |                    0 |
| N/A   47C    P0             520W / 700W |  61411MiB / 81559MiB |    100%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   1  NVIDIA H100 80GB HBM3          On  | 00000000:2D:00.0 Off |                    0 |
| N/A   51C    P0             512W / 700W |  61409MiB / 81559MiB |    100%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   2  NVIDIA H100 80GB HBM3          On  | 00000000:3F:00.0 Off |                    0 |
| N/A   30C    P0             116W / 700W |  14627MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   3  NVIDIA H100 80GB HBM3          On  | 00000000:66:00.0 Off |                    0 |
| N/A   27C    P0              72W / 700W |      5MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   4  NVIDIA H100 80GB HBM3          On  | 00000000:9B:00.0 Off |                    0 |
| N/A   37C    P0             305W / 700W |  61395MiB / 81559MiB |    100%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   5  NVIDIA H100 80GB HBM3          On  | 00000000:AE:00.0 Off |                    0 |
| N/A   51C    P0             502W / 700W |  20302MiB / 81559MiB |     96%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   6  NVIDIA H100 80GB HBM3          On  | 00000000:BF:00.0 Off |                    0 |
| N/A   67C    P0             694W / 700W |  30083MiB / 81559MiB |     98%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   7  NVIDIA H100 80GB HBM3          On  | 00000000:E4:00.0 Off |                    0 |
| N/A   61C    P0             658W / 700W |  30083MiB / 81559MiB |    100%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A     50628      C   python3                                   61398MiB |
|    1   N/A  N/A     27683      C   python3                                   61396MiB |
|    2   N/A  N/A   2984539      C   python                                    14618MiB |
|    4   N/A  N/A   3631350      C   python3                                   61382MiB |
|    5   N/A  N/A    206289      C   ...niconda3/envs/fokin_HCNN/bin/python    19102MiB |
|    5   N/A  N/A    233158      C   ...niconda3/envs/fokin_HCNN/bin/python     1184MiB |
|    6   N/A  N/A    107896      C   .../envs/chertkov_llmtelora/bin/python    30074MiB |
|    7   N/A  N/A    107897      C   .../envs/chertkov_llmtelora/bin/python    30074MiB |
+---------------------------------------------------------------------------------------+

====================================================================================================
step:0/20000 val_loss:7.0496 train_time:1.30s step_avg:nanms
step:100/20000 avg_train_loss:4.4009 time:258s step_avg:301ms
step:200/20000 avg_train_loss:2.6687 time:288s step_avg:301ms
step:300/20000 avg_train_loss:2.1306 time:318s step_avg:301ms
step:400/20000 avg_train_loss:1.9161 time:348s step_avg:301ms
step:500/20000 avg_train_loss:1.7485 time:378s step_avg:301ms
step:500/20000 val_loss:1.7185 train_time:147.54s step_avg:301ms
step:600/20000 avg_train_loss:1.6641 time:425s step_avg:301ms
step:700/20000 avg_train_loss:1.6019 time:455s step_avg:301ms
step:800/20000 avg_train_loss:1.5285 time:485s step_avg:301ms
step:900/20000 avg_train_loss:1.5022 time:515s step_avg:301ms
step:1000/20000 avg_train_loss:1.4724 time:545s step_avg:301ms
step:1000/20000 val_loss:1.4729 train_time:298.11s step_avg:301ms
step:1100/20000 avg_train_loss:1.4449 time:584s step_avg:301ms
step:1200/20000 avg_train_loss:1.4392 time:614s step_avg:301ms
step:1300/20000 avg_train_loss:1.4325 time:644s step_avg:301ms
step:1400/20000 avg_train_loss:1.3802 time:674s step_avg:301ms
step:1500/20000 avg_train_loss:1.4329 time:704s step_avg:301ms
step:1500/20000 val_loss:1.3819 train_time:448.63s step_avg:301ms
step:1600/20000 avg_train_loss:1.3742 time:743s step_avg:301ms
step:1700/20000 avg_train_loss:1.3763 time:773s step_avg:301ms
step:1800/20000 avg_train_loss:1.3653 time:803s step_avg:301ms
step:1900/20000 avg_train_loss:1.3503 time:833s step_avg:301ms
step:2000/20000 avg_train_loss:1.3438 time:863s step_avg:301ms
step:2000/20000 val_loss:1.3287 train_time:599.15s step_avg:301ms
step:2100/20000 avg_train_loss:1.3165 time:902s step_avg:301ms
step:2200/20000 avg_train_loss:1.3162 time:932s step_avg:301ms
step:2300/20000 avg_train_loss:1.3176 time:962s step_avg:301ms
step:2400/20000 avg_train_loss:1.2778 time:992s step_avg:301ms
step:2500/20000 avg_train_loss:1.2921 time:1022s step_avg:301ms
step:2500/20000 val_loss:1.2931 train_time:749.65s step_avg:301ms
step:2600/20000 avg_train_loss:1.2751 time:1061s step_avg:301ms
step:2700/20000 avg_train_loss:1.2689 time:1091s step_avg:301ms
step:2800/20000 avg_train_loss:1.2581 time:1121s step_avg:301ms
step:2900/20000 avg_train_loss:1.2683 time:1151s step_avg:301ms
step:3000/20000 avg_train_loss:1.2732 time:1181s step_avg:301ms
step:3000/20000 val_loss:1.2651 train_time:900.17s step_avg:301ms
step:3100/20000 avg_train_loss:1.2250 time:1220s step_avg:301ms
step:3200/20000 avg_train_loss:1.2701 time:1250s step_avg:301ms
step:3300/20000 avg_train_loss:1.2408 time:1280s step_avg:301ms
step:3400/20000 avg_train_loss:1.2427 time:1310s step_avg:301ms
step:3500/20000 avg_train_loss:1.2203 time:1340s step_avg:301ms
step:3500/20000 val_loss:1.2412 train_time:1050.69s step_avg:301ms
step:3600/20000 avg_train_loss:1.2438 time:1379s step_avg:301ms
step:3700/20000 avg_train_loss:1.2762 time:1409s step_avg:301ms
step:3800/20000 avg_train_loss:1.2676 time:1439s step_avg:301ms
step:3900/20000 avg_train_loss:1.2575 time:1469s step_avg:301ms
step:4000/20000 avg_train_loss:1.2041 time:1499s step_avg:301ms
step:4000/20000 val_loss:1.2263 train_time:1201.24s step_avg:301ms
step:4100/20000 avg_train_loss:1.1946 time:1538s step_avg:301ms
step:4200/20000 avg_train_loss:1.2335 time:1563s step_avg:300ms
step:4300/20000 avg_train_loss:1.2097 time:1593s step_avg:300ms
step:4400/20000 avg_train_loss:1.1915 time:1623s step_avg:300ms
step:4500/20000 avg_train_loss:1.2343 time:1653s step_avg:300ms
step:4500/20000 val_loss:1.2083 train_time:1346.49s step_avg:300ms
step:4600/20000 avg_train_loss:1.2317 time:1691s step_avg:300ms
step:4700/20000 avg_train_loss:1.2111 time:1721s step_avg:300ms
step:4800/20000 avg_train_loss:1.1919 time:1752s step_avg:300ms
step:4900/20000 avg_train_loss:1.2197 time:1782s step_avg:300ms
step:5000/20000 avg_train_loss:1.2097 time:1812s step_avg:300ms
step:5000/20000 val_loss:1.1962 train_time:1497.03s step_avg:300ms
step:5100/20000 avg_train_loss:1.1907 time:1857s step_avg:301ms
step:5200/20000 avg_train_loss:1.2063 time:1887s step_avg:301ms
step:5300/20000 avg_train_loss:1.1789 time:1918s step_avg:301ms
step:5400/20000 avg_train_loss:1.2225 time:1948s step_avg:301ms
step:5500/20000 avg_train_loss:1.1891 time:1978s step_avg:301ms
step:5500/20000 val_loss:1.1874 train_time:1654.47s step_avg:301ms
step:5600/20000 avg_train_loss:1.1722 time:2016s step_avg:301ms
step:5700/20000 avg_train_loss:1.1482 time:2046s step_avg:301ms
step:5800/20000 avg_train_loss:1.1718 time:2076s step_avg:301ms
step:5900/20000 avg_train_loss:1.1908 time:2107s step_avg:301ms
step:6000/20000 avg_train_loss:1.1666 time:2137s step_avg:301ms
step:6000/20000 val_loss:1.1756 train_time:1805.00s step_avg:301ms
step:6100/20000 avg_train_loss:1.1751 time:2175s step_avg:301ms
step:6200/20000 avg_train_loss:1.1576 time:2205s step_avg:301ms
step:6300/20000 avg_train_loss:1.1610 time:2235s step_avg:301ms
step:6400/20000 avg_train_loss:1.1858 time:2266s step_avg:301ms
step:6500/20000 avg_train_loss:1.1621 time:2296s step_avg:301ms
step:6500/20000 val_loss:1.1668 train_time:1955.53s step_avg:301ms
step:6600/20000 avg_train_loss:1.1839 time:2334s step_avg:301ms
step:6700/20000 avg_train_loss:1.1639 time:2364s step_avg:301ms
step:6800/20000 avg_train_loss:1.1845 time:2394s step_avg:301ms
step:6900/20000 avg_train_loss:1.1631 time:2425s step_avg:301ms
step:7000/20000 avg_train_loss:1.1296 time:2455s step_avg:301ms
step:7000/20000 val_loss:1.1600 train_time:2106.08s step_avg:301ms
step:7100/20000 avg_train_loss:1.1622 time:2493s step_avg:301ms
step:7200/20000 avg_train_loss:1.1542 time:2523s step_avg:301ms
step:7300/20000 avg_train_loss:1.1551 time:2553s step_avg:301ms
step:7400/20000 avg_train_loss:1.1611 time:2583s step_avg:301ms
step:7500/20000 avg_train_loss:1.1660 time:2614s step_avg:301ms
step:7500/20000 val_loss:1.1526 train_time:2256.60s step_avg:301ms
step:7600/20000 avg_train_loss:1.1644 time:2652s step_avg:301ms
step:7700/20000 avg_train_loss:1.1792 time:2682s step_avg:301ms
step:7800/20000 avg_train_loss:1.1713 time:2711s step_avg:301ms
step:7900/20000 avg_train_loss:1.1653 time:2741s step_avg:301ms
step:8000/20000 avg_train_loss:1.1978 time:2771s step_avg:301ms
step:8000/20000 val_loss:1.1488 train_time:2405.75s step_avg:301ms
step:8100/20000 avg_train_loss:1.1407 time:2810s step_avg:301ms
step:8200/20000 avg_train_loss:1.1699 time:2840s step_avg:301ms
step:8300/20000 avg_train_loss:1.1346 time:2870s step_avg:301ms
step:8400/20000 avg_train_loss:1.1502 time:2900s step_avg:301ms
step:8500/20000 avg_train_loss:1.1421 time:2930s step_avg:301ms
step:8500/20000 val_loss:1.1414 train_time:2556.28s step_avg:301ms
step:8600/20000 avg_train_loss:1.1249 time:2969s step_avg:301ms
step:8700/20000 avg_train_loss:1.1440 time:2999s step_avg:301ms
step:8800/20000 avg_train_loss:1.1341 time:3029s step_avg:301ms
step:8900/20000 avg_train_loss:1.1417 time:3059s step_avg:301ms
step:9000/20000 avg_train_loss:1.1320 time:3089s step_avg:301ms
step:9000/20000 val_loss:1.1366 train_time:2706.80s step_avg:301ms
step:9100/20000 avg_train_loss:1.1652 time:3125s step_avg:301ms
step:9200/20000 avg_train_loss:1.1248 time:3140s step_avg:299ms
step:9300/20000 avg_train_loss:1.1101 time:3154s step_avg:297ms
step:9400/20000 avg_train_loss:1.1203 time:3170s step_avg:296ms
step:9500/20000 avg_train_loss:1.1053 time:3184s step_avg:294ms
step:9500/20000 val_loss:1.1294 train_time:2793.09s step_avg:294ms
step:9600/20000 avg_train_loss:1.1395 time:3203s step_avg:293ms
step:9700/20000 avg_train_loss:1.1639 time:3218s step_avg:291ms
step:9800/20000 avg_train_loss:1.1239 time:3232s step_avg:290ms
step:9900/20000 avg_train_loss:1.1248 time:3246s step_avg:288ms
step:10000/20000 avg_train_loss:1.0999 time:3260s step_avg:287ms
step:10000/20000 val_loss:1.1253 train_time:2865.70s step_avg:287ms
step:10100/20000 avg_train_loss:1.0910 time:3280s step_avg:286ms
step:10200/20000 avg_train_loss:1.0897 time:3294s step_avg:284ms
step:10300/20000 avg_train_loss:1.1003 time:3308s step_avg:283ms
step:10400/20000 avg_train_loss:1.1003 time:3322s step_avg:281ms
step:10500/20000 avg_train_loss:1.0936 time:3336s step_avg:280ms
step:10500/20000 val_loss:1.1207 train_time:2938.10s step_avg:280ms
step:10600/20000 avg_train_loss:1.1566 time:3354s step_avg:279ms
step:10700/20000 avg_train_loss:1.0780 time:3370s step_avg:278ms
step:10800/20000 avg_train_loss:1.1445 time:3390s step_avg:277ms
step:10900/20000 avg_train_loss:1.1255 time:3420s step_avg:277ms
step:11000/20000 avg_train_loss:1.1151 time:3451s step_avg:277ms
step:11000/20000 val_loss:1.1170 train_time:3048.59s step_avg:277ms
step:11100/20000 avg_train_loss:1.1151 time:3489s step_avg:278ms
step:11200/20000 avg_train_loss:1.1379 time:3519s step_avg:278ms
step:11300/20000 avg_train_loss:1.1172 time:3540s step_avg:277ms
step:11400/20000 avg_train_loss:1.1196 time:3570s step_avg:277ms
step:11500/20000 avg_train_loss:1.0783 time:3600s step_avg:278ms
step:11500/20000 val_loss:1.1125 train_time:3189.68s step_avg:278ms
step:11600/20000 avg_train_loss:1.1303 time:3639s step_avg:278ms
step:11700/20000 avg_train_loss:1.0890 time:3669s step_avg:278ms
step:11800/20000 avg_train_loss:1.0849 time:3699s step_avg:278ms
step:11900/20000 avg_train_loss:1.0896 time:3729s step_avg:278ms
step:12000/20000 avg_train_loss:1.0959 time:3759s step_avg:279ms
step:12000/20000 val_loss:1.1102 train_time:3340.30s step_avg:279ms
step:12100/20000 avg_train_loss:1.0787 time:3798s step_avg:279ms
step:12200/20000 avg_train_loss:1.0988 time:3828s step_avg:279ms
step:12300/20000 avg_train_loss:1.1147 time:3858s step_avg:279ms
step:12400/20000 avg_train_loss:1.0661 time:3888s step_avg:279ms
step:12500/20000 avg_train_loss:1.0812 time:3918s step_avg:279ms
step:12500/20000 val_loss:1.1059 train_time:3490.93s step_avg:279ms
step:12600/20000 avg_train_loss:1.0990 time:3957s step_avg:280ms
step:12700/20000 avg_train_loss:1.0793 time:3987s step_avg:280ms
step:12800/20000 avg_train_loss:1.0826 time:4017s step_avg:280ms
step:12900/20000 avg_train_loss:1.0854 time:4047s step_avg:280ms
step:13000/20000 avg_train_loss:1.1302 time:4077s step_avg:280ms
step:13000/20000 val_loss:1.1024 train_time:3641.53s step_avg:280ms
step:13100/20000 avg_train_loss:1.1283 time:4116s step_avg:280ms
step:13200/20000 avg_train_loss:1.1400 time:4146s step_avg:281ms
step:13300/20000 avg_train_loss:1.0674 time:4176s step_avg:281ms
step:13400/20000 avg_train_loss:1.0798 time:4206s step_avg:281ms
step:13500/20000 avg_train_loss:1.0834 time:4236s step_avg:281ms
step:13500/20000 val_loss:1.0994 train_time:3792.16s step_avg:281ms
step:13600/20000 avg_train_loss:1.0921 time:4275s step_avg:281ms
step:13700/20000 avg_train_loss:1.0766 time:4305s step_avg:281ms
step:13800/20000 avg_train_loss:1.0895 time:4335s step_avg:282ms
step:13900/20000 avg_train_loss:1.1158 time:4365s step_avg:282ms
step:14000/20000 avg_train_loss:1.0777 time:4395s step_avg:282ms
step:14000/20000 val_loss:1.0964 train_time:3942.81s step_avg:282ms
step:14100/20000 avg_train_loss:1.0930 time:4434s step_avg:282ms
step:14200/20000 avg_train_loss:1.0879 time:4464s step_avg:282ms
step:14300/20000 avg_train_loss:1.1077 time:4494s step_avg:282ms
step:14400/20000 avg_train_loss:1.0828 time:4524s step_avg:282ms
step:14500/20000 avg_train_loss:1.0837 time:4554s step_avg:282ms
step:14500/20000 val_loss:1.0945 train_time:4093.40s step_avg:282ms
step:14600/20000 avg_train_loss:1.0816 time:4593s step_avg:283ms
step:14700/20000 avg_train_loss:1.1108 time:4623s step_avg:283ms
step:14800/20000 avg_train_loss:1.0869 time:4653s step_avg:283ms
step:14900/20000 avg_train_loss:1.0642 time:4683s step_avg:283ms
step:15000/20000 avg_train_loss:1.0646 time:4714s step_avg:283ms
step:15000/20000 val_loss:1.0923 train_time:4244.01s step_avg:283ms
step:15100/20000 avg_train_loss:1.0483 time:4759s step_avg:284ms
step:15200/20000 avg_train_loss:1.0828 time:4789s step_avg:284ms
step:15300/20000 avg_train_loss:1.0767 time:4819s step_avg:284ms
step:15400/20000 avg_train_loss:1.0762 time:4849s step_avg:284ms
step:15500/20000 avg_train_loss:1.0657 time:4880s step_avg:284ms
step:15500/20000 val_loss:1.0900 train_time:4401.56s step_avg:284ms
step:15600/20000 avg_train_loss:1.0831 time:4918s step_avg:284ms
step:15700/20000 avg_train_loss:1.0769 time:4948s step_avg:284ms
step:15800/20000 avg_train_loss:1.0731 time:4973s step_avg:284ms
step:15900/20000 avg_train_loss:1.1018 time:5003s step_avg:284ms
step:16000/20000 avg_train_loss:1.0745 time:5033s step_avg:284ms
step:16000/20000 val_loss:1.0880 train_time:4546.83s step_avg:284ms
step:16100/20000 avg_train_loss:1.0929 time:5072s step_avg:284ms
step:16200/20000 avg_train_loss:1.0849 time:5102s step_avg:285ms
step:16300/20000 avg_train_loss:1.0687 time:5132s step_avg:285ms
step:16400/20000 avg_train_loss:1.0575 time:5162s step_avg:285ms
step:16500/20000 avg_train_loss:1.0649 time:5192s step_avg:285ms
step:16500/20000 val_loss:1.0862 train_time:4697.43s step_avg:285ms
step:16600/20000 avg_train_loss:1.0739 time:5231s step_avg:285ms
step:16700/20000 avg_train_loss:1.0695 time:5261s step_avg:285ms
step:16800/20000 avg_train_loss:1.0898 time:5291s step_avg:285ms
step:16900/20000 avg_train_loss:1.0853 time:5321s step_avg:285ms
step:17000/20000 avg_train_loss:1.1030 time:5351s step_avg:285ms
step:17000/20000 val_loss:1.0844 train_time:4848.22s step_avg:285ms
step:17100/20000 avg_train_loss:1.1027 time:5390s step_avg:285ms
step:17200/20000 avg_train_loss:1.0878 time:5420s step_avg:286ms
step:17300/20000 avg_train_loss:1.0991 time:5450s step_avg:286ms
step:17400/20000 avg_train_loss:1.1069 time:5481s step_avg:286ms
step:17500/20000 avg_train_loss:1.0764 time:5511s step_avg:286ms
step:17500/20000 val_loss:1.0833 train_time:4999.08s step_avg:286ms
step:17600/20000 avg_train_loss:1.0510 time:5549s step_avg:286ms
step:17700/20000 avg_train_loss:1.1023 time:5580s step_avg:286ms
step:17800/20000 avg_train_loss:1.0648 time:5610s step_avg:286ms
step:17900/20000 avg_train_loss:1.0610 time:5640s step_avg:286ms
step:18000/20000 avg_train_loss:1.0643 time:5670s step_avg:286ms
step:18000/20000 val_loss:1.0817 train_time:5149.96s step_avg:286ms
step:18100/20000 avg_train_loss:1.0759 time:5709s step_avg:286ms
step:18200/20000 avg_train_loss:1.0537 time:5739s step_avg:286ms
step:18300/20000 avg_train_loss:1.0646 time:5769s step_avg:287ms
step:18400/20000 avg_train_loss:1.0894 time:5799s step_avg:287ms
step:18500/20000 avg_train_loss:1.0903 time:5829s step_avg:287ms
step:18500/20000 val_loss:1.0803 train_time:5300.85s step_avg:287ms
step:18600/20000 avg_train_loss:1.0362 time:5868s step_avg:287ms
step:18700/20000 avg_train_loss:1.0604 time:5899s step_avg:287ms
step:18800/20000 avg_train_loss:1.0352 time:5930s step_avg:287ms
step:18900/20000 avg_train_loss:1.0769 time:5960s step_avg:287ms
step:19000/20000 avg_train_loss:1.0907 time:5990s step_avg:287ms
step:19000/20000 val_loss:1.0788 train_time:5452.97s step_avg:287ms
step:19100/20000 avg_train_loss:1.0933 time:6029s step_avg:287ms
step:19200/20000 avg_train_loss:1.0394 time:6059s step_avg:287ms
step:19300/20000 avg_train_loss:1.0563 time:6089s step_avg:287ms
step:19400/20000 avg_train_loss:1.0316 time:6119s step_avg:287ms
step:19500/20000 avg_train_loss:1.0432 time:6149s step_avg:288ms
step:19500/20000 val_loss:1.0766 train_time:5603.87s step_avg:288ms
step:19600/20000 avg_train_loss:1.0200 time:6188s step_avg:288ms
step:19700/20000 avg_train_loss:1.0474 time:6218s step_avg:288ms
step:19800/20000 avg_train_loss:1.0437 time:6248s step_avg:288ms
step:19900/20000 avg_train_loss:1.0769 time:6278s step_avg:288ms
step:20000/20000 avg_train_loss:1.0898 time:6309s step_avg:288ms
step:20000/20000 val_loss:1.1040 train_time:5754.72s step_avg:288ms
Total training time: 6322.73s
