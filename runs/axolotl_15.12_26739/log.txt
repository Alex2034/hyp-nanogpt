====================================================================================================
import os
import sys
with open(sys.argv[0]) as f:
    code = f.read() # read the code of this file ASAP, for logging
import multiprocessing

import random
import datetime
import time
from torch.utils.tensorboard import SummaryWriter
import json

import glob
from dataclasses import dataclass
from transformers import PreTrainedTokenizerFast

import numpy as np
import math
import torch
from torch import nn
import torch.nn.functional as F
import torch.distributed as dist
import torch._inductor.config as config
from torch.nn.parallel import DistributedDataParallel as DDP

from lib.lorentz.manifold import CustomLorentz
from lib.geoopt.optim import RiemannianSGD

import argparse

torch.set_float32_matmul_precision('high')
os.environ["TOKENIZERS_PARALLELISM"] = "false"

# -----------------------------------------------------------------------------
# Muon optimizer

def zeropower_via_svd(G, steps=None):
    U, S, V = G.svd()
    return U @ V.T

@torch.compile
def zeropower_via_newtonschulz5(G, steps=10, eps=1e-7):
    """
    Newton-Schulz iteration to compute the zeroth power / orthogonalization of G. We opt to use a
    quintic iteration whose coefficients are selected to maximize the slope at zero. For the purpose
    of minimizing steps, it turns out to be empirically effective to keep increasing the slope at
    zero even beyond the point where the iteration no longer converges all the way to one everywhere
    on the interval. This iteration therefore does not produce UV^T but rather something like US'V^T
    where S' is diagonal with S_{ii}' \sim Uniform(0.5, 1.5), which turns out not to hurt model
    performance at all relative to UV^T, where USV^T = G is the SVD.
    """
    assert len(G.shape) == 2
    a, b, c = (3.4445, -4.7750,  2.0315)
    X = G.bfloat16()
    X /= (X.norm() + eps) # ensure top singular value <= 1
    if G.size(0) > G.size(1):
        X = X.T
    for _ in range(steps):
        A = X @ X.T
        B = A @ X
        X = a * X + b * B + c * A @ B
    if G.size(0) > G.size(1):
        X = X.T
    return X

zeropower_backends = dict(svd=zeropower_via_svd, newtonschulz5=zeropower_via_newtonschulz5)

class Muon(torch.optim.Optimizer):
    """
    Muon - MomentUm Orthogonalized by Newton-schulz

    Muon internally runs standard SGD-momentum, and then performs an orthogonalization post-
    processing step, in which each 2D parameter's update is replaced with the nearest orthogonal
    matrix. To efficiently orthogonalize each update, we use a Newton-Schulz iteration, which has
    the advantage that it can be stably run in bfloat16 on the GPU.

    Some warnings:
    - This optimizer assumes that all parameters passed in are 2D.
    - It should not be used for the embedding layer, the final fully connected layer, or any {0,1}-D
    parameters; those should all be optimized by a standard method (e.g., AdamW).
    - To use it with 4D convolutional filters, it works well to just flatten their last 3 dimensions.
    - We believe it is unlikely to work well for training with small batch size.
    - We believe it may not work well for finetuning pretrained models, but we haven't tested this.
    - We have not yet tried this optimizer for training scenarios larger than NanoGPT (124M).

    Arguments:
        lr: The learning rate used by the internal SGD.
        momentum: The momentum used by the internal SGD.
        nesterov: Whether to use Nesterov-style momentum in the internal SGD. (recommended)
        backend: The chosen backend for the orthogonalization step. (recommended: 'newtonschulz5')
        backend_steps: The number of iteration steps to use in the backend, if it is iterative.
    """
    def __init__(self, params, lr=0.02, momentum=0.95, nesterov=True,
                 backend='newtonschulz5', backend_steps=5):
        defaults = dict(lr=lr, momentum=momentum, nesterov=nesterov, backend=backend, backend_steps=backend_steps)
        super().__init__(params, defaults)

    def step(self):

        for group in self.param_groups:

            lr = group['lr']
            momentum = group['momentum']
            zeropower_backend = zeropower_backends[group['backend']]

            # generate weight updates in distributed fashion
            total_params = sum(p.numel() for p in group['params'])
            updates_flat = torch.zeros(total_params, device='cuda', dtype=torch.bfloat16)
            curr_idx = 0
            for i, p in enumerate(group['params']):
                # luckily this will perfectly distribute a transformer with multiple of 4 layers to 8 GPUs
                if i % int(os.environ['WORLD_SIZE']) == int(os.environ['RANK']):
                    g = p.grad
                    assert g is not None
                    state = self.state[p]
                    if 'momentum_buffer' not in state:
                        state['momentum_buffer'] = torch.zeros_like(g)
                    buf = state['momentum_buffer']
                    buf.mul_(momentum).add_(g)
                    if group['nesterov']:
                        g = g.add(buf, alpha=momentum)
                    g = zeropower_backend(g, steps=group['backend_steps'])
                    g *= max(1, g.size(0)/g.size(1))**0.5
                    updates_flat[curr_idx:curr_idx+p.numel()] = g.flatten()
                curr_idx += p.numel()

            # sync updates across devices. we are not memory-constrained so can do this simple deserialization
            dist.all_reduce(updates_flat, op=dist.ReduceOp.SUM)

            # deserialize and apply updates
            curr_idx = 0
            for p in group['params']:
                g = updates_flat[curr_idx:curr_idx+p.numel()].view_as(p.data).type_as(p.data)
                p.data.add_(g, alpha=-lr)
                curr_idx += p.numel()

# -----------------------------------------------------------------------------
# PyTorch nn.Module definitions for the GPT-2 model

class Rotary(torch.nn.Module):

    def __init__(self, dim, base=10000):
        super().__init__()
        self.inv_freq = 1.0 / (base ** (torch.arange(0, dim, 2).float() / dim))
        self.seq_len_cached = None
        self.cos_cached = None
        self.sin_cached = None

    def forward(self, x):
        seq_len = x.shape[1]
        if seq_len != self.seq_len_cached:
            self.seq_len_cached = seq_len
            t = torch.arange(seq_len, device=x.device).type_as(self.inv_freq)
            freqs = torch.outer(t, self.inv_freq).to(x.device)
            self.cos_cached = freqs.cos().bfloat16()
            self.sin_cached = freqs.sin().bfloat16()
        return self.cos_cached[None, :, None, :], self.sin_cached[None, :, None, :]

def apply_rotary_emb(x, cos, sin):
    assert x.ndim == 4 # multihead attention
    d = x.shape[3]//2
    x1 = x[..., :d]
    x2 = x[..., d:]
    y1 = x1 * cos + x2 * sin
    y2 = x1 * (-sin) + x2 * cos
    return torch.cat([y1, y2], 3).type_as(x)

class CausalSelfAttention(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.n_head = config.n_head
        self.n_embd = config.n_embd
        self.head_dim = self.n_embd // self.n_head
        assert self.n_embd % self.n_head == 0
        self.c_q = nn.Linear(self.n_embd, self.n_embd, bias=False)
        self.c_k = nn.Linear(self.n_embd, self.n_embd, bias=False)
        self.c_v = nn.Linear(self.n_embd, self.n_embd, bias=False)
        # output projection
        self.c_proj = nn.Linear(self.n_embd, self.n_embd, bias=False)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977
        self.rotary = Rotary(self.head_dim)

    def forward(self, x):
        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)
        q = self.c_q(x).view(B, T, self.n_head, self.head_dim)
        k = self.c_k(x).view(B, T, self.n_head, self.head_dim)
        v = self.c_v(x).view(B, T, self.n_head, self.head_dim)
        cos, sin = self.rotary(q)
        q, k = F.rms_norm(q, (q.size(-1),)), F.rms_norm(k, (k.size(-1),)) # QK norm suggested by @Grad62304977
        q, k = apply_rotary_emb(q, cos, sin), apply_rotary_emb(k, cos, sin)
        y = F.scaled_dot_product_attention(q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2), is_causal=True)
        y = y.transpose(1, 2).contiguous().view_as(x) # re-assemble all head outputs side by side
        y = self.c_proj(y)
        return y

class MLP(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd, bias=False)
        self.c_proj  = nn.Linear(4 * config.n_embd, config.n_embd, bias=False)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977

    def forward(self, x):
        x = self.c_fc(x)
        x = F.relu(x).square() # https://arxiv.org/abs/2109.08668v2; ~1-2% better than GELU; suggested by @SKYLINEZ007 and @Grad62304977
        x = self.c_proj(x)
        return x

class Block(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.attn = CausalSelfAttention(config)
        self.mlp = MLP(config)

    def forward(self, x):
        x = x + self.attn(F.rms_norm(x, (x.size(-1),)))
        x = x + self.mlp(F.rms_norm(x, (x.size(-1),)))
        return x

class LorentzMLR(nn.Module):
    """ Multinomial logistic regression (MLR) in the Lorentz model
    """
    def __init__(
            self, 
            manifold: CustomLorentz, 
            num_features: int, 
            num_classes: int
        ):
        super(LorentzMLR, self).__init__()

        self.manifold = manifold

        self.a = torch.nn.Parameter(torch.zeros(num_classes,))
        self.z = torch.nn.Parameter(F.pad(torch.zeros(num_classes, num_features-2), pad=(1,0), value=1)) # z should not be (0,0)

        self.init_weights()

    def forward(self, x):
        # x: (B, T, num_features)

        # Hyperplane parameters
        sqrt_mK = 1 / self.manifold.k.sqrt()  # scalar
        norm_z = torch.norm(self.z, dim=-1)  # (num_classes,)
        w_t = torch.sinh(sqrt_mK * self.a) * norm_z  # (num_classes,)
        w_s = torch.cosh(sqrt_mK * self.a).unsqueeze(-1) * self.z  # (num_classes, num_features -1)

        beta = torch.sqrt(-w_t**2 + torch.norm(w_s, dim=-1)**2)  # (num_classes,)

        x0 = x.narrow(-1, 0, 1)  # (B, T, 1)
        x_rest = x.narrow(-1, 1, x.shape[-1]-1)  # (B, T, num_features -1)
        inner_prod = torch.matmul(x_rest, self.z.T)  # (B, T, num_classes)
        alpha = -x0 * w_t.view(1, 1, -1) + torch.cosh(sqrt_mK * self.a).view(1, 1, -1) * inner_prod  # (B, T, num_classes)
        sqrt_mK_alpha_over_beta = sqrt_mK * alpha / beta.view(1, 1, -1)
        d = self.manifold.k.sqrt() * torch.abs(torch.asinh(sqrt_mK_alpha_over_beta))  # (B, T, num_classes)

        logits = torch.sign(alpha) * beta.view(1, 1, -1) * d  # (B, T, num_classes)

        return logits

    def init_weights(self):
        stdv = 1. / math.sqrt(self.z.size(1))
        nn.init.uniform_(self.z, -stdv, stdv)
        nn.init.uniform_(self.a, -stdv, stdv)

# -----------------------------------------------------------------------------
# The main GPT-2 model

@dataclass
class GPTConfig:
    vocab_size : int = 50304
    n_layer : int = 12
    n_head : int = 6 # head dim 128 suggested by @Grad62304977
    n_embd : int = 784
    lm_head : str = 'euc'
    curvature : float = 1.0

class GPT(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.config = config

        self.transformer = nn.ModuleDict(dict(
            wte = nn.Embedding(config.vocab_size, config.n_embd),
            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),
        ))

        if config.lm_head == 'euc':
            self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)
            self.lm_head.weight.data.zero_()

        elif config.lm_head == 'hyp':
            self.manifold = CustomLorentz(k=torch.tensor([config.curvature]))
            self.lm_head = LorentzMLR(
                manifold=self.manifold,
                num_features=config.n_embd,
                num_classes=config.vocab_size
            )
        else:
            raise ValueError("Invalid lm_head, choose 'euc'/'hyp'.")

    def forward(self, idx, targets=None, return_logits=True):

        # forward the GPT model itself
        x = self.transformer.wte(idx) # token embeddings of shape (b, t, n_embd)
        x = F.rms_norm(x, (x.size(-1),))
        for block in self.transformer.h:
            x = block(x)
        x = F.rms_norm(x, (x.size(-1),))

        if targets is not None:
            # if we are given some desired targets also calculate the loss
            logits = self.lm_head(x)
            logits = logits.float() # use tf32/fp32 for logits
            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)
        else:
            # inference-time mini-optimization: only forward the lm_head on the very last position
            logits = self.lm_head(x[:, [-1], :]) # note: using list [-1] to preserve the time dim
            logits = logits.float() # use tf32/fp32 for logits
            loss = None

        # there are performance reasons why not returning logits is prudent, if not needed
        if not return_logits:
            logits = None

        return logits, loss

# -----------------------------------------------------------------------------
# Our own simple Distributed Data Loader

def _peek_data_shard(filename):
    # only reads the header, returns header data
    with open(filename, "rb") as f:
        # first read the header, which is 256 int32 integers (4 bytes each)
        header = np.frombuffer(f.read(256*4), dtype=np.int32)
    if header[0] != 20240520:
        print("ERROR: magic number mismatch in the data .bin file!")
        print("---> HINT: Are you passing in a correct file with --input_bin?")
        print("---> HINT: Dataset encoding changed recently, re-run data prepro or refer again to README")
        print("---> HINT: For example re-run: `python dev/data/tinyshakespeare.py`, then re-try")
        exit(1)
    assert header[1] == 1, "unsupported version"
    ntok = header[2] # number of tokens (claimed)
    return ntok # for now just return the number of tokens

def _load_data_shard(filename):
    with open(filename, "rb") as f:
        # first read the header, which is 256 int32 integers (4 bytes each)
        header = np.frombuffer(f.read(256*4), dtype=np.int32)
        assert header[0] == 20240520, "magic number mismatch in the data .bin file"
        assert header[1] == 1, "unsupported version"
        ntok = header[2] # number of tokens (claimed)
        # the rest of it are tokens, stored as uint16
        tokens = np.frombuffer(f.read(), dtype=np.uint16)
    assert len(tokens) == ntok, "number of tokens read does not match header?"
    return tokens

class DistributedDataLoader:
    def __init__(self, filename_pattern, B, T, process_rank, num_processes):
        self.process_rank = process_rank
        self.num_processes = num_processes
        self.B = B
        self.T = T

        # glob files that match the pattern
        self.files = sorted(glob.glob(filename_pattern))
        assert len(self.files) > 0, f"did not find any files that match the pattern {filename_pattern}"

        # load and validate all data shards, count number of tokens in total
        ntok_total = 0
        for fname in self.files:
            shard_ntok = _peek_data_shard(fname)
            assert shard_ntok >= num_processes * B * T + 1
            ntok_total += int(shard_ntok)
        self.ntok_total = ntok_total

        # kick things off
        self.reset()

    def reset(self):
        self.current_shard = 0
        self.current_position = self.process_rank * self.B * self.T
        self.tokens = _load_data_shard(self.files[self.current_shard])

    def advance(self): # advance to next data shard
        self.current_shard = (self.current_shard + 1) % len(self.files)
        self.current_position = self.process_rank * self.B * self.T
        self.tokens = _load_data_shard(self.files[self.current_shard])

    def next_batch(self):
        B = self.B
        T = self.T
        buf = self.tokens[self.current_position : self.current_position+B*T+1]
        buf = torch.tensor(buf.astype(np.int32), dtype=torch.long)
        x = (buf[:-1]).view(B, T) # inputs
        y = (buf[1:]).view(B, T) # targets
        # advance current position and load next shard if necessary
        self.current_position += B * T * self.num_processes
        if self.current_position + (B * T * self.num_processes + 1) > len(self.tokens):
            self.advance()
        return x.cuda(), y.cuda()

def generate_text(model, context, max_length=200, temperature=1.0, top_k=50):
    model.eval()
    generated = context.clone()
    for _ in range(max_length):
        with torch.no_grad():
            logits, _ = model(generated, return_logits=True)
            logits = logits[:, -1, :] / temperature
            if top_k > 0:
                values, indices = torch.topk(logits, top_k)
                logits[logits < values[:, [-1]]] = -float('Inf')
            probs = F.softmax(logits, dim=-1)
            next_token = torch.multinomial(probs, num_samples=1)
            generated = torch.cat((generated, next_token), dim=1)
    return generated

def encode_text(text):
    """Encodes a string into token IDs."""
    return tokenizer.encode(text, return_tensors="pt").to(device)

def decode_tokens(tokens):
    """Decodes token IDs into a readable string."""
    return tokenizer.decode(tokens.cpu().tolist(), skip_special_tokens=True)


# -----------------------------------------------------------------------------
# int main

@dataclass
class Hyperparameters:
    # data hyperparams
    # input_bin : str = 'data/fineweb10B/fineweb_train_*.bin' # input .bin to train on
    # input_val_bin : str = 'data/fineweb10B/fineweb_val_*.bin' # input .bin to eval validation loss on
    data_path : str = 'data/tinystories'
    input_bin : str = 'data/tinystories/train.bin' # input .bin to train on
    input_val_bin : str = 'data/tinystories/val.bin' # input .bin to eval validation loss on
    num_vocab : int = 1000
    # optimization hyperparams
    batch_size : int = 64 # batch size, in sequences, across all devices
    device_batch_size : int = 64 # batch size, in sequences, per device
    sequence_length : int = 1024 # sequence length, in tokens
    num_iterations : int = 20_000 # number of iterations to run (for FW 2.7B was 4578)
    warmup_iters : int = 100
    warmdown_iters : int = 100 # number of iterations of linear warmup/warmdown for triangular or trapezoidal schedule
    weight_decay : float = 0
    # evaluation and logging hyperparams
    generate_every : int = 5000
    train_loss_every : int = 100 
    val_loss_every : int = 500 # every how many steps to evaluate val loss? 0 for only at the end
    val_tokens : int = 6160384 # how many tokens of validation data? it's important to keep this fixed for consistent comparisons
    save_every : int = 0 # every how many steps to save the checkpoint? 0 for only at the end
    # model
    vocab_size : int = 1000
    n_layer : int = 12
    n_head : int = 6 # head dim 128 suggested by @Grad62304977
    n_embd : int = 384
    lm_head : str = 'hyp'
    curvature : float = 1.0


parser = argparse.ArgumentParser(description="Train GPT model with customizable parameters.")
parser.add_argument(
    "--curvature",
    type=float,
    default=1.0,
    help="Set the curvature for the Lorentz manifold (default: 1.0)"
)

args_from_cli = parser.parse_args()


args = Hyperparameters(curvature=args_from_cli.curvature)

tokenizer = PreTrainedTokenizerFast(
    tokenizer_file=os.path.join(args.data_path, "tinystories_tokenizer.json"),
    eos_token="<|endoftext|>",
    unk_token="[UNK]",
    pad_token="[PAD]"  # Optional, but can be useful
)

# set up DDP (distributed data parallel). torchrun sets this env variable
assert torch.cuda.is_available()
dist.init_process_group(backend='nccl')
ddp_rank = int(os.environ['RANK'])
ddp_local_rank = int(os.environ['LOCAL_RANK'])
ddp_world_size = int(os.environ['WORLD_SIZE'])
device = f'cuda:{ddp_local_rank}'
torch.cuda.set_device(device)
print(f"using device: {device}")
master_process = (ddp_rank == 0) # this process will do logging, checkpointing etc.

# convenience variables
B, T = args.device_batch_size, args.sequence_length
# calculate the number of steps to take in the val loop.
assert args.val_tokens % (B * T * ddp_world_size) == 0
val_steps = args.val_tokens // (B * T * ddp_world_size)
# calculate the steps of gradient accumulation required to attain the desired global batch size.
assert args.batch_size % (B * ddp_world_size) == 0
train_accumulation_steps = args.batch_size // (B * ddp_world_size)

# load tokens
train_loader = DistributedDataLoader(args.input_bin, B, T, ddp_rank, ddp_world_size)
val_loader = DistributedDataLoader(args.input_val_bin, B, T, ddp_rank, ddp_world_size)
if master_process:
    print(f"Training DataLoader: total number of tokens: {train_loader.ntok_total} across {len(train_loader.files)} files")
    print(f"Validation DataLoader: total number of tokens: {val_loader.ntok_total} across {len(val_loader.files)} files")
x, y = train_loader.next_batch()

# there are only 50257 unique GPT-2 tokens; we extend to nearest multiple of 128 for efficiency. suggested to me by @Grad62304977.
# this originates from Karpathy's experiments.
# num_vocab = 50304
model = GPT(GPTConfig(vocab_size=args.num_vocab, 
                      n_layer=args.n_layer, 
                      n_head=args.n_head,
                      n_embd=args.n_embd,
                      lm_head=args.lm_head,
                      curvature=args.curvature))
model = model.cuda()
if hasattr(config, "coordinate_descent_tuning"):
    config.coordinate_descent_tuning = True # suggested by @Chillee
model = torch.compile(model)
# here we wrap model into DDP container
model = DDP(model, device_ids=[ddp_local_rank])
raw_model = model.module # always contains the "raw" unwrapped model
ctx = torch.amp.autocast(device_type='cuda', dtype=torch.bfloat16)

# init the optimizer(s)
# optimizer1 = torch.optim.Adam([raw_model.transformer.wte.weight], lr=0.3,   betas=(0.9, 0.95), fused=True)
# optimizer2 = torch.optim.Adam([raw_model.lm_head.weight],         lr=0.003, betas=(0.9, 0.95), fused=True)
# optimizer3 = Muon(raw_model.transformer.h.parameters(),           lr=0.02,  momentum=0.95)
# optimizers = [optimizer1, optimizer2, optimizer3]
# Fix the `k` parameter 
for name, param in raw_model.named_parameters():
    if "manifold.k" in name:
        param.requires_grad = False
        
lm_head_params = [p for p in raw_model.lm_head.parameters() if p.requires_grad]

params = list(raw_model.transformer.h.parameters())
matrix_params = [p for p in params if p.ndim == 2]
wte_params = [raw_model.transformer.wte.weight]

optimizer_lm_head = RiemannianSGD(
    [{'params': lm_head_params}], lr=0.05, weight_decay=5e-4, momentum=0.9, nesterov=True, stabilize=1
)

optimizer_muon = Muon(matrix_params, lr=0.05, momentum=0.95)

optimizer_wte = torch.optim.Adam(wte_params, lr=0.6, betas=(0.8, 0.95), fused=True)

optimizers = [optimizer_lm_head, optimizer_muon, optimizer_wte]


# learning rate decay scheduler (linear warmup and warmdown)
def get_lr(it):
    assert it <= args.num_iterations
    # 1) linear warmup for warmup_iters steps
    if it < args.warmup_iters:
        return (it+1) / args.warmup_iters
    # 2) constant lr for a while
    elif it >= args.num_iterations - args.warmdown_iters:
        return (args.num_iterations - it) / args.warmdown_iters
    # 3) 
    else:
        decay_ratio = (it - args.warmup_iters) / (args.num_iterations - args.warmup_iters)
        assert 0 <= decay_ratio <= 1
        return 0.1**decay_ratio

schedulers = [torch.optim.lr_scheduler.LambdaLR(opt, get_lr) for opt in optimizers]

# begin logging
if master_process:

    funny_animals = [
        "kinkajou", "platypus", "wombat", "parrot",
        "axolotl", "lemur", "blobfish", "dingo",
        "whale", "quokka", "sloth", "capybara", "emu",
        "koala", "marmoset", "meerkat", "panda"
    ]
    prefix = random.choice(funny_animals)
    now = datetime.datetime.now()
    date_part = now.strftime('%d.%m')  
    seconds_since_midnight = int(time.time() % 86400)
    run_id = f"{prefix}_{date_part}_{seconds_since_midnight}"

    # Create log directory and file
    logdir = f'runs/{run_id}/'
    os.makedirs(logdir, exist_ok=True)
    os.makedirs(os.path.join(logdir, "tensorboard_logs"), exist_ok=True)

    print(f"Logs for this run will be stored in: {logdir}")

    print("Writing logs to: " + os.path.join(logdir, "tensorboard_logs"))
    writer = SummaryWriter(log_dir=os.path.join(logdir, "tensorboard_logs"))

    config_path = os.path.join(logdir, "config.json")
    with open(config_path, "w") as f:
        json.dump(vars(args), f, indent=4)

    def pretty_json(hp):
        json_hp = json.dumps(hp, indent=2)
        return "".join("\t" + line for line in json_hp.splitlines(True))
    
    writer.add_text("run_params", pretty_json(vars(args)))
    logfile = os.path.join(logdir, 'log.txt')
    # create the log file
    with open(logfile, "w") as f:
        # begin the log by printing this file (the Python code)
        f.write('='*100 + '\n')
        f.write(code)
        f.write('='*100 + '\n')
        # log information about the hardware/software environment this is running on
        # and print the full `nvidia-smi` to file
        f.write(f"Running pytorch {torch.version.__version__} compiled for CUDA {torch.version.cuda}\nnvidia-smi:\n")
        import subprocess
        result = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
        f.write(f'{result.stdout}\n')
        f.write('='*100 + '\n')

training_time_s = 0.0
# start the clock
torch.cuda.synchronize()
t0 = time.time()
total_t0 = time.time()
train_loss_accum = 0.0
train_loss_count = 0
# begin training
train_loader.reset()
for step in range(args.num_iterations + 1):
    last_step = (step == args.num_iterations)
    # This effectively ignores timing first 10 steps, which are slower for weird reasons.
    # Alternately, and slightly more correctly in terms of benchmarking, we could do 10
    # steps with dummy data first, and then re-initialize the model and reset the loader.
    if step == 10:
        training_time_s = 0.0
        t0 = time.time()
    timed_steps = float('nan') if step <= 11 else (step - 10) + 1 # <= 11 to avoid bug in val

    # once in a while evaluate the validation dataset
    if (last_step or (args.val_loss_every > 0 and step % args.val_loss_every == 0)):
        # stop the clock
        torch.cuda.synchronize()
        training_time_s += time.time() - t0
        # run validation batches
        model.eval()
        val_loader.reset()
        val_loss = 0.0
        for _ in range(val_steps):
            x_val, y_val = val_loader.next_batch()
            with ctx: # of course, we'd like to use no_grad() here too, but that creates a torch.compile error for some reason
                _, loss = model(x_val, y_val, return_logits=False)
                val_loss += loss.detach()
                del loss
        dist.all_reduce(val_loss, op=dist.ReduceOp.AVG)
        val_loss /= val_steps
        # log val loss to console and to logfile
        if master_process:
            print(f'step:{step}/{args.num_iterations} val_loss:{val_loss:.4f} train_time:{training_time_s:.2f}s step_avg:{1000*training_time_s/(timed_steps-1):.0f}ms')
            with open(logfile, "a") as f:
                f.write(f'step:{step}/{args.num_iterations} val_loss:{val_loss:.4f} train_time:{training_time_s:.2f}s step_avg:{1000*training_time_s/(timed_steps-1):.0f}ms\n')
            writer.add_scalar('Loss/Validation', val_loss.item(), step)
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.time()

    if master_process and (step % args.generate_every == 0 or last_step):
        # Use a fixed prompt or context for generation
        prompt = "Once upon a time"  # Customize as per your dataset
        context = encode_text(prompt)
        
        # Generate text
        generated_tokens = generate_text(raw_model, context, max_length=200, temperature=1.0, top_k=50)
        generated_text = decode_tokens(generated_tokens[0])
        
        # Log the generated text to TensorBoard
        writer.add_text(f"Generated_Text/Step_{step}", generated_text, step)
        
        # Optionally log to console for immediate feedback
        print(f"[Step {step}] Generated Text: {generated_text}")


    if master_process and (last_step or (args.save_every > 0 and step % args.save_every == 0)):
        # stop the clock
        torch.cuda.synchronize()
        training_time_s += time.time() - t0
        # save the state of the training process
        log = dict(step=step, code=code, model=raw_model.state_dict(), optimizers=[opt.state_dict() for opt in optimizers])
        torch.save(log, 'ckpts/%s_state_step%06d.pt' % (run_id, step))
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.time()

    # bit confusing: we want to make sure to eval on 0th iteration
    # but also after the very last iteration. so we loop for step <= num_iterations
    # instead of just < num_iterations (one extra due to <=), only to do
    # the validation/sampling one last time, and then we break right here as we're done.
    if last_step:
        break

    # --------------- TRAINING SECTION BEGIN -----------------
    model.train()
    for i in range(1, train_accumulation_steps+1):
        # forward pass
        with ctx:
            _, loss = model(x, y, return_logits=False)
            train_loss = loss.detach()
        # advance the dataset for the next batch
        x, y = train_loader.next_batch()
        # backward pass
        if i < train_accumulation_steps:
            with model.no_sync(): # there's no need to sync gradients every accumulation step
                loss.backward()
        else:
            loss.backward() # just sync on the last step
    for name, p in model.named_parameters():
        if p.grad is None:
            # print(f"WARNING: Parameter {name} has no gradient. Skipping.")
            continue
        p.grad /= train_accumulation_steps
    # step the optimizers and schedulers
    for opt, sched in zip(optimizers, schedulers):
        opt.step()
        sched.step()
    # null the gradients
    model.zero_grad(set_to_none=True)
    train_loss_accum += train_loss.item()
    train_loss_count += 1
    # --------------- TRAINING SECTION END -------------------
    # everything that follows now is just diagnostics, prints, logging, etc.

    #dist.all_reduce(train_loss, op=dist.ReduceOp.AVG) # all-reducing the training loss would be more correct in terms of logging, but slower
    if master_process and (step+1) % args.train_loss_every == 0:
        avg_train_loss = train_loss_accum / train_loss_count
        elapsed_time = time.time() - total_t0
        approx_time = training_time_s + (time.time() - t0)
        avg_time_per_step = approx_time/timed_steps
        estimated_total_time = avg_time_per_step * args.num_iterations
        print(f"step:{step+1}/{args.num_iterations} avg_train_loss:{avg_train_loss:.4f} time:{elapsed_time:.0f}/{estimated_total_time:.0f}s step_avg:{1000*avg_time_per_step:.0f}ms")
        with open(logfile, "a") as f:
            f.write(f"step:{step+1}/{args.num_iterations} avg_train_loss:{avg_train_loss:.4f} time:{elapsed_time:.0f}s step_avg:{1000*avg_time_per_step:.0f}ms\n")
        writer.add_scalar('Loss/Train', avg_train_loss, step)
        train_loss_accum = 0.0
        train_loss_count = 0

if master_process:
    total_training_time = time.time() - total_t0
    print(f"Total training time: {total_training_time:.2f}s")
    with open(logfile, "a") as f:
        f.write(f"Total training time: {total_training_time:.2f}s\n")
    print(f"peak memory consumption: {torch.cuda.max_memory_allocated() // 1024 // 1024} MiB")

# -------------------------------------------------------------------------
# clean up nice
if master_process:
    writer.close()
dist.destroy_process_group()
====================================================================================================
Running pytorch 2.4.1+cu121 compiled for CUDA 12.1
nvidia-smi:
Sun Dec 15 07:25:39 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.154.05             Driver Version: 535.154.05   CUDA Version: 12.3     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA H100 80GB HBM3          On  | 00000000:19:00.0 Off |                    0 |
| N/A   27C    P0              71W / 700W |      5MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   1  NVIDIA H100 80GB HBM3          On  | 00000000:2D:00.0 Off |                    0 |
| N/A   29C    P0              71W / 700W |      5MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   2  NVIDIA H100 80GB HBM3          On  | 00000000:3F:00.0 Off |                    0 |
| N/A   30C    P0             116W / 700W |  14629MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   3  NVIDIA H100 80GB HBM3          On  | 00000000:66:00.0 Off |                    0 |
| N/A   26C    P0              72W / 700W |      5MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   4  NVIDIA H100 80GB HBM3          On  | 00000000:9B:00.0 Off |                    0 |
| N/A   37C    P0             307W / 700W |  61395MiB / 81559MiB |    100%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   5  NVIDIA H100 80GB HBM3          On  | 00000000:AE:00.0 Off |                    0 |
| N/A   36C    P0             117W / 700W |   1111MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   6  NVIDIA H100 80GB HBM3          On  | 00000000:BF:00.0 Off |                    0 |
| N/A   66C    P0             699W / 700W |  30083MiB / 81559MiB |    100%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   7  NVIDIA H100 80GB HBM3          On  | 00000000:E4:00.0 Off |                    0 |
| N/A   60C    P0             667W / 700W |  30083MiB / 81559MiB |    100%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    2   N/A  N/A   2984539      C   python                                    14620MiB |
|    4   N/A  N/A   3631350      C   python3                                   61382MiB |
|    5   N/A  N/A    374931      C   ...niconda3/envs/fokin_HCNN/bin/python     1100MiB |
|    6   N/A  N/A    107896      C   .../envs/chertkov_llmtelora/bin/python    30074MiB |
|    7   N/A  N/A    107897      C   .../envs/chertkov_llmtelora/bin/python    30074MiB |
+---------------------------------------------------------------------------------------+

====================================================================================================
step:0/20000 val_loss:7.0757 train_time:1.30s step_avg:nanms
step:100/20000 avg_train_loss:4.2544 time:230s step_avg:141ms
step:200/20000 avg_train_loss:2.5079 time:245s step_avg:141ms
step:300/20000 avg_train_loss:2.0190 time:259s step_avg:141ms
step:400/20000 avg_train_loss:1.8381 time:273s step_avg:141ms
step:500/20000 avg_train_loss:1.6888 time:287s step_avg:141ms
step:500/20000 val_loss:1.6631 train_time:69.22s step_avg:141ms
step:600/20000 avg_train_loss:1.6167 time:313s step_avg:141ms
step:700/20000 avg_train_loss:1.5621 time:327s step_avg:141ms
step:800/20000 avg_train_loss:1.4956 time:342s step_avg:141ms
step:900/20000 avg_train_loss:1.4743 time:356s step_avg:141ms
step:1000/20000 avg_train_loss:1.4484 time:370s step_avg:141ms
step:1000/20000 val_loss:1.4508 train_time:139.89s step_avg:141ms
step:1100/20000 avg_train_loss:1.4236 time:388s step_avg:141ms
step:1200/20000 avg_train_loss:1.4209 time:402s step_avg:141ms
step:1300/20000 avg_train_loss:1.4155 time:416s step_avg:141ms
step:1400/20000 avg_train_loss:1.3644 time:430s step_avg:141ms
step:1500/20000 avg_train_loss:1.4178 time:444s step_avg:141ms
step:1500/20000 val_loss:1.3679 train_time:210.56s step_avg:141ms
step:1600/20000 avg_train_loss:1.3600 time:462s step_avg:141ms
step:1700/20000 avg_train_loss:1.3632 time:476s step_avg:141ms
step:1800/20000 avg_train_loss:1.3521 time:490s step_avg:141ms
step:1900/20000 avg_train_loss:1.3376 time:505s step_avg:141ms
step:2000/20000 avg_train_loss:1.3320 time:519s step_avg:141ms
step:2000/20000 val_loss:1.3164 train_time:281.28s step_avg:141ms
step:2100/20000 avg_train_loss:1.3051 time:537s step_avg:141ms
step:2200/20000 avg_train_loss:1.3047 time:551s step_avg:141ms
step:2300/20000 avg_train_loss:1.3070 time:565s step_avg:141ms
step:2400/20000 avg_train_loss:1.2674 time:579s step_avg:141ms
step:2500/20000 avg_train_loss:1.2809 time:593s step_avg:141ms
step:2500/20000 val_loss:1.2820 train_time:352.16s step_avg:141ms
step:2600/20000 avg_train_loss:1.2643 time:611s step_avg:141ms
step:2700/20000 avg_train_loss:1.2586 time:625s step_avg:141ms
step:2800/20000 avg_train_loss:1.2481 time:640s step_avg:141ms
step:2900/20000 avg_train_loss:1.2581 time:654s step_avg:141ms
step:3000/20000 avg_train_loss:1.2632 time:668s step_avg:141ms
step:3000/20000 val_loss:1.2546 train_time:423.06s step_avg:141ms
step:3100/20000 avg_train_loss:1.2146 time:686s step_avg:142ms
step:3200/20000 avg_train_loss:1.2598 time:700s step_avg:142ms
step:3300/20000 avg_train_loss:1.2306 time:714s step_avg:142ms
step:3400/20000 avg_train_loss:1.2329 time:729s step_avg:142ms
step:3500/20000 avg_train_loss:1.2104 time:743s step_avg:142ms
step:3500/20000 val_loss:1.2322 train_time:493.98s step_avg:142ms
step:3600/20000 avg_train_loss:1.2348 time:761s step_avg:142ms
step:3700/20000 avg_train_loss:1.2670 time:775s step_avg:142ms
step:3800/20000 avg_train_loss:1.2579 time:789s step_avg:142ms
step:3900/20000 avg_train_loss:1.2481 time:803s step_avg:142ms
step:4000/20000 avg_train_loss:1.1941 time:817s step_avg:142ms
step:4000/20000 val_loss:1.2162 train_time:564.88s step_avg:142ms
step:4100/20000 avg_train_loss:1.1847 time:835s step_avg:142ms
step:4200/20000 avg_train_loss:1.2236 time:850s step_avg:142ms
step:4300/20000 avg_train_loss:1.2001 time:864s step_avg:142ms
step:4400/20000 avg_train_loss:1.1818 time:878s step_avg:142ms
step:4500/20000 avg_train_loss:1.2246 time:892s step_avg:142ms
step:4500/20000 val_loss:1.1990 train_time:635.79s step_avg:142ms
step:4600/20000 avg_train_loss:1.2220 time:910s step_avg:142ms
step:4700/20000 avg_train_loss:1.2018 time:924s step_avg:142ms
step:4800/20000 avg_train_loss:1.1820 time:938s step_avg:142ms
step:4900/20000 avg_train_loss:1.2104 time:953s step_avg:142ms
step:5000/20000 avg_train_loss:1.2001 time:967s step_avg:142ms
step:5000/20000 val_loss:1.1866 train_time:706.72s step_avg:142ms
step:5100/20000 avg_train_loss:1.1812 time:986s step_avg:142ms
step:5200/20000 avg_train_loss:1.1970 time:1000s step_avg:142ms
step:5300/20000 avg_train_loss:1.1693 time:1014s step_avg:142ms
step:5400/20000 avg_train_loss:1.2130 time:1029s step_avg:142ms
step:5500/20000 avg_train_loss:1.1795 time:1043s step_avg:142ms
step:5500/20000 val_loss:1.1772 train_time:779.04s step_avg:142ms
step:5600/20000 avg_train_loss:1.1625 time:1061s step_avg:142ms
step:5700/20000 avg_train_loss:1.1381 time:1075s step_avg:142ms
step:5800/20000 avg_train_loss:1.1623 time:1089s step_avg:142ms
step:5900/20000 avg_train_loss:1.1810 time:1103s step_avg:142ms
step:6000/20000 avg_train_loss:1.1568 time:1117s step_avg:142ms
step:6000/20000 val_loss:1.1667 train_time:849.94s step_avg:142ms
step:6100/20000 avg_train_loss:1.1655 time:1135s step_avg:142ms
step:6200/20000 avg_train_loss:1.1479 time:1150s step_avg:142ms
step:6300/20000 avg_train_loss:1.1513 time:1164s step_avg:142ms
step:6400/20000 avg_train_loss:1.1762 time:1178s step_avg:142ms
step:6500/20000 avg_train_loss:1.1526 time:1192s step_avg:142ms
step:6500/20000 val_loss:1.1568 train_time:920.86s step_avg:142ms
step:6600/20000 avg_train_loss:1.1744 time:1210s step_avg:142ms
step:6700/20000 avg_train_loss:1.1538 time:1224s step_avg:142ms
step:6800/20000 avg_train_loss:1.1747 time:1238s step_avg:142ms
step:6900/20000 avg_train_loss:1.1533 time:1253s step_avg:142ms
step:7000/20000 avg_train_loss:1.1196 time:1267s step_avg:142ms
step:7000/20000 val_loss:1.1505 train_time:991.73s step_avg:142ms
step:7100/20000 avg_train_loss:1.1524 time:1285s step_avg:142ms
step:7200/20000 avg_train_loss:1.1450 time:1299s step_avg:142ms
step:7300/20000 avg_train_loss:1.1457 time:1313s step_avg:142ms
step:7400/20000 avg_train_loss:1.1514 time:1327s step_avg:142ms
step:7500/20000 avg_train_loss:1.1565 time:1342s step_avg:142ms
step:7500/20000 val_loss:1.1433 train_time:1062.65s step_avg:142ms
step:7600/20000 avg_train_loss:1.1556 time:1359s step_avg:142ms
step:7700/20000 avg_train_loss:1.1690 time:1374s step_avg:142ms
step:7800/20000 avg_train_loss:1.1618 time:1388s step_avg:142ms
step:7900/20000 avg_train_loss:1.1557 time:1402s step_avg:142ms
step:8000/20000 avg_train_loss:1.1884 time:1416s step_avg:142ms
step:8000/20000 val_loss:1.1388 train_time:1133.57s step_avg:142ms
step:8100/20000 avg_train_loss:1.1312 time:1434s step_avg:142ms
step:8200/20000 avg_train_loss:1.1604 time:1448s step_avg:142ms
step:8300/20000 avg_train_loss:1.1249 time:1463s step_avg:142ms
step:8400/20000 avg_train_loss:1.1402 time:1477s step_avg:142ms
step:8500/20000 avg_train_loss:1.1320 time:1491s step_avg:142ms
step:8500/20000 val_loss:1.1318 train_time:1204.51s step_avg:142ms
step:8600/20000 avg_train_loss:1.1151 time:1509s step_avg:142ms
step:8700/20000 avg_train_loss:1.1343 time:1523s step_avg:142ms
step:8800/20000 avg_train_loss:1.1244 time:1537s step_avg:142ms
step:8900/20000 avg_train_loss:1.1322 time:1551s step_avg:142ms
step:9000/20000 avg_train_loss:1.1229 time:1566s step_avg:142ms
step:9000/20000 val_loss:1.1265 train_time:1275.40s step_avg:142ms
step:9100/20000 avg_train_loss:1.1555 time:1584s step_avg:142ms
step:9200/20000 avg_train_loss:1.1152 time:1598s step_avg:142ms
step:9300/20000 avg_train_loss:1.1001 time:1612s step_avg:142ms
step:9400/20000 avg_train_loss:1.1107 time:1627s step_avg:142ms
step:9500/20000 avg_train_loss:1.0957 time:1641s step_avg:142ms
step:9500/20000 val_loss:1.1192 train_time:1347.56s step_avg:142ms
step:9600/20000 avg_train_loss:1.1294 time:1659s step_avg:142ms
step:9700/20000 avg_train_loss:1.1547 time:1674s step_avg:142ms
step:9800/20000 avg_train_loss:1.1142 time:1688s step_avg:142ms
step:9900/20000 avg_train_loss:1.1150 time:1702s step_avg:142ms
step:10000/20000 avg_train_loss:1.0901 time:1716s step_avg:142ms
step:10000/20000 val_loss:1.1156 train_time:1418.45s step_avg:142ms
step:10100/20000 avg_train_loss:1.0808 time:1736s step_avg:142ms
step:10200/20000 avg_train_loss:1.0805 time:1750s step_avg:142ms
step:10300/20000 avg_train_loss:1.0906 time:1764s step_avg:142ms
step:10400/20000 avg_train_loss:1.0902 time:1778s step_avg:142ms
step:10500/20000 avg_train_loss:1.0835 time:1792s step_avg:142ms
step:10500/20000 val_loss:1.1108 train_time:1490.79s step_avg:142ms
step:10600/20000 avg_train_loss:1.1467 time:1810s step_avg:142ms
step:10700/20000 avg_train_loss:1.0686 time:1824s step_avg:142ms
step:10800/20000 avg_train_loss:1.1347 time:1839s step_avg:142ms
step:10900/20000 avg_train_loss:1.1158 time:1853s step_avg:142ms
step:11000/20000 avg_train_loss:1.1054 time:1867s step_avg:142ms
step:11000/20000 val_loss:1.1070 train_time:1561.60s step_avg:142ms
step:11100/20000 avg_train_loss:1.1052 time:1885s step_avg:142ms
step:11200/20000 avg_train_loss:1.1281 time:1899s step_avg:142ms
step:11300/20000 avg_train_loss:1.1078 time:1913s step_avg:142ms
step:11400/20000 avg_train_loss:1.1095 time:1927s step_avg:142ms
step:11500/20000 avg_train_loss:1.0684 time:1941s step_avg:142ms
step:11500/20000 val_loss:1.1024 train_time:1632.45s step_avg:142ms
step:11600/20000 avg_train_loss:1.1206 time:1959s step_avg:142ms
step:11700/20000 avg_train_loss:1.0791 time:1974s step_avg:142ms
step:11800/20000 avg_train_loss:1.0748 time:1988s step_avg:142ms
step:11900/20000 avg_train_loss:1.0798 time:2002s step_avg:142ms
step:12000/20000 avg_train_loss:1.0860 time:2016s step_avg:142ms
step:12000/20000 val_loss:1.1000 train_time:1703.24s step_avg:142ms
step:12100/20000 avg_train_loss:1.0689 time:2034s step_avg:142ms
step:12200/20000 avg_train_loss:1.0892 time:2048s step_avg:142ms
step:12300/20000 avg_train_loss:1.1050 time:2062s step_avg:142ms
step:12400/20000 avg_train_loss:1.0559 time:2076s step_avg:142ms
step:12500/20000 avg_train_loss:1.0711 time:2091s step_avg:142ms
step:12500/20000 val_loss:1.0958 train_time:1774.03s step_avg:142ms
step:12600/20000 avg_train_loss:1.0888 time:2108s step_avg:142ms
step:12700/20000 avg_train_loss:1.0691 time:2123s step_avg:142ms
step:12800/20000 avg_train_loss:1.0725 time:2137s step_avg:142ms
step:12900/20000 avg_train_loss:1.0758 time:2151s step_avg:142ms
step:13000/20000 avg_train_loss:1.1206 time:2165s step_avg:142ms
step:13000/20000 val_loss:1.0924 train_time:1844.85s step_avg:142ms
step:13100/20000 avg_train_loss:1.1184 time:2183s step_avg:142ms
step:13200/20000 avg_train_loss:1.1301 time:2197s step_avg:142ms
step:13300/20000 avg_train_loss:1.0569 time:2211s step_avg:142ms
step:13400/20000 avg_train_loss:1.0696 time:2226s step_avg:142ms
step:13500/20000 avg_train_loss:1.0729 time:2240s step_avg:142ms
step:13500/20000 val_loss:1.0899 train_time:1915.67s step_avg:142ms
step:13600/20000 avg_train_loss:1.0820 time:2258s step_avg:142ms
step:13700/20000 avg_train_loss:1.0664 time:2272s step_avg:142ms
step:13800/20000 avg_train_loss:1.0792 time:2286s step_avg:142ms
step:13900/20000 avg_train_loss:1.1056 time:2300s step_avg:142ms
step:14000/20000 avg_train_loss:1.0675 time:2314s step_avg:142ms
step:14000/20000 val_loss:1.0866 train_time:1986.44s step_avg:142ms
step:14100/20000 avg_train_loss:1.0832 time:2332s step_avg:142ms
step:14200/20000 avg_train_loss:1.0777 time:2346s step_avg:142ms
step:14300/20000 avg_train_loss:1.0975 time:2361s step_avg:142ms
step:14400/20000 avg_train_loss:1.0731 time:2375s step_avg:142ms
step:14500/20000 avg_train_loss:1.0735 time:2389s step_avg:142ms
step:14500/20000 val_loss:1.0841 train_time:2057.35s step_avg:142ms
step:14600/20000 avg_train_loss:1.0715 time:2407s step_avg:142ms
step:14700/20000 avg_train_loss:1.1004 time:2421s step_avg:142ms
step:14800/20000 avg_train_loss:1.0766 time:2435s step_avg:142ms
step:14900/20000 avg_train_loss:1.0536 time:2449s step_avg:142ms
step:15000/20000 avg_train_loss:1.0542 time:2464s step_avg:142ms
step:15000/20000 val_loss:1.0823 train_time:2128.19s step_avg:142ms
step:15100/20000 avg_train_loss:1.0380 time:2483s step_avg:142ms
step:15200/20000 avg_train_loss:1.0726 time:2497s step_avg:142ms
step:15300/20000 avg_train_loss:1.0662 time:2511s step_avg:142ms
step:15400/20000 avg_train_loss:1.0660 time:2525s step_avg:142ms
step:15500/20000 avg_train_loss:1.0554 time:2540s step_avg:142ms
step:15500/20000 val_loss:1.0800 train_time:2200.44s step_avg:142ms
step:15600/20000 avg_train_loss:1.0727 time:2557s step_avg:142ms
step:15700/20000 avg_train_loss:1.0667 time:2572s step_avg:142ms
step:15800/20000 avg_train_loss:1.0628 time:2586s step_avg:142ms
step:15900/20000 avg_train_loss:1.0918 time:2600s step_avg:142ms
step:16000/20000 avg_train_loss:1.0637 time:2614s step_avg:142ms
step:16000/20000 val_loss:1.0778 train_time:2271.28s step_avg:142ms
step:16100/20000 avg_train_loss:1.0823 time:2632s step_avg:142ms
step:16200/20000 avg_train_loss:1.0747 time:2646s step_avg:142ms
step:16300/20000 avg_train_loss:1.0584 time:2660s step_avg:142ms
step:16400/20000 avg_train_loss:1.0470 time:2675s step_avg:142ms
step:16500/20000 avg_train_loss:1.0548 time:2689s step_avg:142ms
step:16500/20000 val_loss:1.0760 train_time:2342.09s step_avg:142ms
step:16600/20000 avg_train_loss:1.0635 time:2707s step_avg:142ms
step:16700/20000 avg_train_loss:1.0593 time:2721s step_avg:142ms
step:16800/20000 avg_train_loss:1.0797 time:2735s step_avg:142ms
step:16900/20000 avg_train_loss:1.0752 time:2749s step_avg:142ms
step:17000/20000 avg_train_loss:1.0924 time:2763s step_avg:142ms
step:17000/20000 val_loss:1.0742 train_time:2412.97s step_avg:142ms
step:17100/20000 avg_train_loss:1.0924 time:2781s step_avg:142ms
step:17200/20000 avg_train_loss:1.0777 time:2795s step_avg:142ms
step:17300/20000 avg_train_loss:1.0889 time:2810s step_avg:142ms
step:17400/20000 avg_train_loss:1.0969 time:2824s step_avg:142ms
step:17500/20000 avg_train_loss:1.0659 time:2838s step_avg:142ms
step:17500/20000 val_loss:1.0731 train_time:2483.83s step_avg:142ms
step:17600/20000 avg_train_loss:1.0406 time:2856s step_avg:142ms
step:17700/20000 avg_train_loss:1.0921 time:2870s step_avg:142ms
step:17800/20000 avg_train_loss:1.0540 time:2884s step_avg:142ms
step:17900/20000 avg_train_loss:1.0507 time:2898s step_avg:142ms
step:18000/20000 avg_train_loss:1.0539 time:2913s step_avg:142ms
step:18000/20000 val_loss:1.0715 train_time:2554.67s step_avg:142ms
step:18100/20000 avg_train_loss:1.0657 time:2931s step_avg:142ms
step:18200/20000 avg_train_loss:1.0432 time:2945s step_avg:142ms
step:18300/20000 avg_train_loss:1.0544 time:2959s step_avg:142ms
step:18400/20000 avg_train_loss:1.0791 time:2973s step_avg:142ms
step:18500/20000 avg_train_loss:1.0796 time:2987s step_avg:142ms
step:18500/20000 val_loss:1.0704 train_time:2625.49s step_avg:142ms
step:18600/20000 avg_train_loss:1.0252 time:3005s step_avg:142ms
step:18700/20000 avg_train_loss:1.0500 time:3021s step_avg:142ms
step:18800/20000 avg_train_loss:1.0247 time:3035s step_avg:142ms
step:18900/20000 avg_train_loss:1.0660 time:3049s step_avg:142ms
step:19000/20000 avg_train_loss:1.0803 time:3063s step_avg:142ms
step:19000/20000 val_loss:1.0687 train_time:2697.56s step_avg:142ms
step:19100/20000 avg_train_loss:1.0832 time:3081s step_avg:142ms
step:19200/20000 avg_train_loss:1.0288 time:3095s step_avg:142ms
step:19300/20000 avg_train_loss:1.0455 time:3109s step_avg:142ms
step:19400/20000 avg_train_loss:1.0207 time:3123s step_avg:142ms
step:19500/20000 avg_train_loss:1.0330 time:3138s step_avg:142ms
step:19500/20000 val_loss:1.0666 train_time:2768.35s step_avg:142ms
step:19600/20000 avg_train_loss:1.0095 time:3156s step_avg:142ms
step:19700/20000 avg_train_loss:1.0364 time:3170s step_avg:142ms
step:19800/20000 avg_train_loss:1.0326 time:3184s step_avg:142ms
step:19900/20000 avg_train_loss:1.0664 time:3198s step_avg:142ms
step:20000/20000 avg_train_loss:1.0799 time:3212s step_avg:142ms
step:20000/20000 val_loss:1.0943 train_time:2839.18s step_avg:142ms
Total training time: 3217.61s
