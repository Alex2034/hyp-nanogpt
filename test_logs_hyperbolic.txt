W1215 18:58:30.274547 140287170742080 torch/distributed/run.py:779] 
W1215 18:58:30.274547 140287170742080 torch/distributed/run.py:779] *****************************************
W1215 18:58:30.274547 140287170742080 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1215 18:58:30.274547 140287170742080 torch/distributed/run.py:779] *****************************************
using device: cuda:0
using device: cuda:1
Training DataLoader: total number of tokens: 611289391 across 1 files
Validation DataLoader: total number of tokens: 6150326 across 1 files
Logs for this run will be stored in: runs/15.12_68322_hyp_1000.0/
Writing logs to: runs/15.12_68322_hyp_1000.0/tensorboard_logs
step:0/20000 val_loss:7.0686 train_time:1.25s step_avg:nanms
[rank0]:W1215 19:00:10.449011 140524662458176 torch/_dynamo/convert_frame.py:762] [0/8] torch._dynamo hit config.cache_size_limit (8)
[rank0]:W1215 19:00:10.449011 140524662458176 torch/_dynamo/convert_frame.py:762] [0/8]    function: 'forward' (train_gpt2_hyp.py:306)
[rank0]:W1215 19:00:10.449011 140524662458176 torch/_dynamo/convert_frame.py:762] [0/8]    last reason: GLOBAL_STATE changed: grad_mode 
[rank0]:W1215 19:00:10.449011 140524662458176 torch/_dynamo/convert_frame.py:762] [0/8] To log all recompilation reasons, use TORCH_LOGS="recompiles".
[rank0]:W1215 19:00:10.449011 140524662458176 torch/_dynamo/convert_frame.py:762] [0/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
[rank0]:W1215 19:01:12.340791 140524662458176 torch/_dynamo/convert_frame.py:762] [1/96] torch._dynamo hit config.cache_size_limit (8)
[rank0]:W1215 19:01:12.340791 140524662458176 torch/_dynamo/convert_frame.py:762] [1/96]    function: 'forward' (train_gpt2_hyp.py:218)
[rank0]:W1215 19:01:12.340791 140524662458176 torch/_dynamo/convert_frame.py:762] [1/96]    last reason: L['self'].attn.rotary.seq_len_cached == 10                  
[rank0]:W1215 19:01:12.340791 140524662458176 torch/_dynamo/convert_frame.py:762] [1/96] To log all recompilation reasons, use TORCH_LOGS="recompiles".
[rank0]:W1215 19:01:12.340791 140524662458176 torch/_dynamo/convert_frame.py:762] [1/96] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
[rank0]:W1215 19:02:05.328932 140524662458176 torch/_dynamo/convert_frame.py:762] [3/96] torch._dynamo hit config.cache_size_limit (8)
[rank0]:W1215 19:02:05.328932 140524662458176 torch/_dynamo/convert_frame.py:762] [3/96]    function: 'forward' (train_gpt2_hyp.py:184)
[rank0]:W1215 19:02:05.328932 140524662458176 torch/_dynamo/convert_frame.py:762] [3/96]    last reason: L['self'].rotary.seq_len_cached == 18                       
[rank0]:W1215 19:02:05.328932 140524662458176 torch/_dynamo/convert_frame.py:762] [3/96] To log all recompilation reasons, use TORCH_LOGS="recompiles".
[rank0]:W1215 19:02:05.328932 140524662458176 torch/_dynamo/convert_frame.py:762] [3/96] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
[Step 0] Generated Text: ĠOnce Ġupon Ġa Ġtime Ġloo Ġcol Ġsh ood ing Ġbl ag Ġwalking Ġwas Ġeat ust Ġcall Ġhead % 'm Ġcould les ort ach Ġsoon Ġdid side Ġhas Ġmade Ġnam nna ight Ġli Ġle ĠHis ( ion Ġabout Ġst st k us C ´ ic Ġfrom ĠS Ġhead ally ob on Ċ Ġafter = ream ll Ġfish Ġtre Ġbed Ġlo Q uddenly Ġmore llow q el urpr Ġtheir ve Ġdecided Ġrock Ġcat Ġch Ġlist Ġunt Ġwar Ġfo Ġus Ġlove Ġlot ith Ġra ĠT Ġa ch ĠSo Ġnoticed ened hat oy ~ bbit Ġget ĠC Ġstill s w ou Ġme ust Ġgra Ġlove Ġliked ĠTimmy Ġvo nn Ġout Ġher ĠM Ġcame 7 ound Ġenjoy Ġsmiled Ġlook m us ed Ġde Ġwr other W ened Ġknow Ġcry Ġbeauti an c Ġin Ġend Ġbr ¸ 7 Ġab E Ġdown Ġremember et fu i ort urn ally Ġremember Ġas Ġover ar Ġbro Ġcouldn Ġget Ġclimb Ġday Ġokay Ġwalk Ġlong ally ob ĠT P ľ » ted Ġbed ĠH ~ sed Ġon Ġher ed Ġke . ¥ 2 ¼ Ġhard ĠLucy Ġbeaut Ġmu ĠIt Ġad Ġsm ĠSara i wn and Ġmy Ġnext ain Ġfor Ġshould Q ¶ Ġthanked 7 Ġfound | ," Æ oth pt Ġbeautiful Ġmo Ġdon bb Ġha
step:100/20000 avg_train_loss:4.1322 time:225/1480s step_avg:74ms
step:200/20000 avg_train_loss:2.3859 time:233/1478s step_avg:74ms
step:300/20000 avg_train_loss:1.9321 time:240/1479s step_avg:74ms
step:400/20000 avg_train_loss:1.7798 time:247/1478s step_avg:74ms
step:500/20000 avg_train_loss:1.6355 time:255/1478s step_avg:74ms
step:500/20000 val_loss:1.6202 train_time:36.22s step_avg:74ms
step:600/20000 avg_train_loss:1.5745 time:273/1478s step_avg:74ms
step:700/20000 avg_train_loss:1.5313 time:280/1478s step_avg:74ms
step:800/20000 avg_train_loss:1.4661 time:288/1478s step_avg:74ms
step:900/20000 avg_train_loss:1.4502 time:295/1478s step_avg:74ms
step:1000/20000 avg_train_loss:1.4312 time:302/1478s step_avg:74ms
step:1000/20000 val_loss:1.4314 train_time:73.14s step_avg:74ms
step:1100/20000 avg_train_loss:1.4094 time:312/1478s step_avg:74ms
step:1200/20000 avg_train_loss:1.3993 time:319/1478s step_avg:74ms
step:1300/20000 avg_train_loss:1.3950 time:327/1478s step_avg:74ms
step:1400/20000 avg_train_loss:1.3427 time:334/1478s step_avg:74ms
step:1500/20000 avg_train_loss:1.4054 time:341/1478s step_avg:74ms
step:1500/20000 val_loss:1.3552 train_time:110.09s step_avg:74ms
step:1600/20000 avg_train_loss:1.3475 time:351/1478s step_avg:74ms
step:1700/20000 avg_train_loss:1.3533 time:358/1478s step_avg:74ms
step:1800/20000 avg_train_loss:1.3338 time:365/1478s step_avg:74ms
step:1900/20000 avg_train_loss:1.3217 time:373/1478s step_avg:74ms
step:2000/20000 avg_train_loss:1.3210 time:380/1478s step_avg:74ms
step:2000/20000 val_loss:1.3076 train_time:147.02s step_avg:74ms
step:2100/20000 avg_train_loss:1.2949 time:390/1478s step_avg:74ms
step:2200/20000 avg_train_loss:1.2922 time:397/1478s step_avg:74ms
step:2300/20000 avg_train_loss:1.2975 time:404/1478s step_avg:74ms
step:2400/20000 avg_train_loss:1.2590 time:412/1478s step_avg:74ms
step:2500/20000 avg_train_loss:1.2804 time:419/1478s step_avg:74ms
step:2500/20000 val_loss:1.2741 train_time:183.96s step_avg:74ms
step:2600/20000 avg_train_loss:1.2592 time:429/1478s step_avg:74ms
step:2700/20000 avg_train_loss:1.2531 time:436/1478s step_avg:74ms
step:2800/20000 avg_train_loss:1.2437 time:443/1478s step_avg:74ms
step:2900/20000 avg_train_loss:1.2538 time:451/1478s step_avg:74ms
step:3000/20000 avg_train_loss:1.2550 time:458/1477s step_avg:74ms
step:3000/20000 val_loss:1.2483 train_time:220.88s step_avg:74ms
step:3100/20000 avg_train_loss:1.2020 time:468/1477s step_avg:74ms
step:3200/20000 avg_train_loss:1.2493 time:475/1478s step_avg:74ms
step:3300/20000 avg_train_loss:1.2264 time:482/1478s step_avg:74ms
step:3400/20000 avg_train_loss:1.2241 time:490/1478s step_avg:74ms
step:3500/20000 avg_train_loss:1.2049 time:497/1478s step_avg:74ms
step:3500/20000 val_loss:1.2261 train_time:257.84s step_avg:74ms
step:3600/20000 avg_train_loss:1.2309 time:507/1478s step_avg:74ms
step:3700/20000 avg_train_loss:1.2624 time:514/1478s step_avg:74ms
step:3800/20000 avg_train_loss:1.2487 time:521/1478s step_avg:74ms
step:3900/20000 avg_train_loss:1.2373 time:529/1477s step_avg:74ms
step:4000/20000 avg_train_loss:1.1919 time:536/1477s step_avg:74ms
step:4000/20000 val_loss:1.2102 train_time:294.76s step_avg:74ms
step:4100/20000 avg_train_loss:1.1791 time:546/1478s step_avg:74ms
step:4200/20000 avg_train_loss:1.2177 time:553/1478s step_avg:74ms
step:4300/20000 avg_train_loss:1.1910 time:560/1478s step_avg:74ms
step:4400/20000 avg_train_loss:1.1795 time:568/1478s step_avg:74ms
step:4500/20000 avg_train_loss:1.2173 time:575/1478s step_avg:74ms
step:4500/20000 val_loss:1.1937 train_time:331.71s step_avg:74ms
step:4600/20000 avg_train_loss:1.2136 time:585/1478s step_avg:74ms
step:4700/20000 avg_train_loss:1.1929 time:592/1478s step_avg:74ms
step:4800/20000 avg_train_loss:1.1827 time:599/1478s step_avg:74ms
step:4900/20000 avg_train_loss:1.2000 time:607/1477s step_avg:74ms
step:5000/20000 avg_train_loss:1.1989 time:614/1478s step_avg:74ms
step:5000/20000 val_loss:1.1822 train_time:368.65s step_avg:74ms
[Step 5000] Generated Text: ĠOnce Ġupon Ġa Ġtime ĠOnce Ġupon Ġa Ġtime , Ġthere Ġwas Ġa Ġlittle Ġgirl Ġnamed ĠLily . ĠShe Ġloved Ġsw eet s Ġand Ġalways Ġwanted Ġto Ġhave Ġfun . ĠOne Ġday , Ġshe Ġfound Ġa Ġh ook Ġin Ġthe Ġpark . ĠShe Ġthought Ġthe Ġh ook Ġwas Ġshiny Ġand Ġgre en Ġand Ġshe Ġput Ġit Ġon Ġher Ġhead . ĠĊ Ċ Lily Ġs at Ġdown Ġand Ġstarted Ġplaying Ġwith Ġthe Ġsw eet Ġtoy . ĠSuddenly , Ġher Ġlittle Ġbr other Ġcame Ġrun ning Ġin . ĠHe Ġasked Ġif Ġthey Ġcould Ġplay Ġtogether Ġand Ġsh ared Ġthe Ġh ook . ĠLily Ġwas Ġhappy Ġto Ġshare Ġand Ġthey Ġhad Ġa Ġlot Ġof Ġfun Ġtogether . Ċ Ċ A fter Ġplaying Ġfor Ġa Ġwhile , ĠLily Ġdecided Ġto Ġfind Ġan other Ġh ook . ĠShe Ġfound Ġone Ġand Ġput Ġit Ġon Ġher Ġhead Ġagain . ĠT h is Ġtime , ĠLily Ġwas Ġcareful Ġnot Ġto Ġm is s Ġthe Ġh ook . ĠShe Ġdecided Ġto Ġshow Ġit Ġto Ġher Ġfriends Ġwho Ġwere Ġplaying Ġa Ġg ame . ĠThey Ġall Ġthought Ġit Ġwas Ġa Ġf ine Ġh ook Ġto Ġplay Ġwith Ġtoo . ĠOnce Ġupon Ġa Ġtime , Ġthere Ġwas Ġa Ġboy Ġnamed ĠTimmy . ĠHe Ġloved
step:5100/20000 avg_train_loss:1.1759 time:625/1483s step_avg:74ms
step:5200/20000 avg_train_loss:1.1948 time:632/1483s step_avg:74ms
step:5300/20000 avg_train_loss:1.1604 time:640/1483s step_avg:74ms
step:5400/20000 avg_train_loss:1.2147 time:647/1483s step_avg:74ms
step:5500/20000 avg_train_loss:1.1641 time:655/1483s step_avg:74ms
step:5500/20000 val_loss:1.1725 train_time:407.02s step_avg:74ms
step:5600/20000 avg_train_loss:1.1538 time:664/1483s step_avg:74ms
step:5700/20000 avg_train_loss:1.1269 time:671/1483s step_avg:74ms
step:5800/20000 avg_train_loss:1.1568 time:679/1483s step_avg:74ms
step:5900/20000 avg_train_loss:1.1804 time:686/1483s step_avg:74ms
step:6000/20000 avg_train_loss:1.1500 time:694/1483s step_avg:74ms
step:6000/20000 val_loss:1.1614 train_time:444.08s step_avg:74ms
step:6100/20000 avg_train_loss:1.1550 time:703/1483s step_avg:74ms
step:6200/20000 avg_train_loss:1.1458 time:711/1483s step_avg:74ms
step:6300/20000 avg_train_loss:1.1447 time:718/1482s step_avg:74ms
step:6400/20000 avg_train_loss:1.1684 time:725/1482s step_avg:74ms
step:6500/20000 avg_train_loss:1.1498 time:733/1482s step_avg:74ms
step:6500/20000 val_loss:1.1521 train_time:481.00s step_avg:74ms
step:6600/20000 avg_train_loss:1.1702 time:742/1482s step_avg:74ms
step:6700/20000 avg_train_loss:1.1449 time:749/1482s step_avg:74ms
step:6800/20000 avg_train_loss:1.1697 time:757/1482s step_avg:74ms
step:6900/20000 avg_train_loss:1.1415 time:764/1482s step_avg:74ms
step:7000/20000 avg_train_loss:1.1226 time:772/1482s step_avg:74ms
step:7000/20000 val_loss:1.1460 train_time:517.91s step_avg:74ms
step:7100/20000 avg_train_loss:1.1406 time:781/1482s step_avg:74ms
step:7200/20000 avg_train_loss:1.1450 time:788/1482s step_avg:74ms
step:7300/20000 avg_train_loss:1.1408 time:796/1482s step_avg:74ms
step:7400/20000 avg_train_loss:1.1471 time:803/1482s step_avg:74ms
step:7500/20000 avg_train_loss:1.1509 time:811/1482s step_avg:74ms
step:7500/20000 val_loss:1.1385 train_time:554.85s step_avg:74ms
step:7600/20000 avg_train_loss:1.1485 time:820/1482s step_avg:74ms
step:7700/20000 avg_train_loss:1.1588 time:827/1482s step_avg:74ms
step:7800/20000 avg_train_loss:1.1582 time:835/1482s step_avg:74ms
step:7900/20000 avg_train_loss:1.1449 time:842/1482s step_avg:74ms
step:8000/20000 avg_train_loss:1.1893 time:850/1482s step_avg:74ms
step:8000/20000 val_loss:1.1343 train_time:591.98s step_avg:74ms
step:8100/20000 avg_train_loss:1.1294 time:859/1482s step_avg:74ms
step:8200/20000 avg_train_loss:1.1497 time:867/1482s step_avg:74ms
step:8300/20000 avg_train_loss:1.1181 time:874/1482s step_avg:74ms
step:8400/20000 avg_train_loss:1.1369 time:881/1482s step_avg:74ms
step:8500/20000 avg_train_loss:1.1373 time:889/1482s step_avg:74ms
step:8500/20000 val_loss:1.1275 train_time:629.02s step_avg:74ms
step:8600/20000 avg_train_loss:1.1117 time:898/1482s step_avg:74ms
step:8700/20000 avg_train_loss:1.1281 time:906/1482s step_avg:74ms
step:8800/20000 avg_train_loss:1.1214 time:913/1482s step_avg:74ms
step:8900/20000 avg_train_loss:1.1294 time:921/1482s step_avg:74ms
step:9000/20000 avg_train_loss:1.1158 time:928/1482s step_avg:74ms
step:9000/20000 val_loss:1.1220 train_time:666.02s step_avg:74ms
step:9100/20000 avg_train_loss:1.1526 time:937/1482s step_avg:74ms
step:9200/20000 avg_train_loss:1.1048 time:945/1482s step_avg:74ms
step:9300/20000 avg_train_loss:1.0990 time:952/1482s step_avg:74ms
step:9400/20000 avg_train_loss:1.1053 time:961/1484s step_avg:74ms
