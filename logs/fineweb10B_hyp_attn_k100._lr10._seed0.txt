W0216 00:38:28.985996 140466949732160 torch/distributed/run.py:779] 
W0216 00:38:28.985996 140466949732160 torch/distributed/run.py:779] *****************************************
W0216 00:38:28.985996 140466949732160 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0216 00:38:28.985996 140466949732160 torch/distributed/run.py:779] *****************************************
[Rank 0] Using device: cuda:0
[Rank 0] This is the master process.
[Rank 0] Training DataLoader: 2700000000 tokens across 27 files.
[Rank 0] Validation DataLoader: 100000000 tokens across 1 files.
[Rank 1] Using device: cuda:1
[Rank 0] Model wrapped in DDP.
k params lengths: head = 0, attn = 12
Tokenizer vocab size: 50304
attn.k is learned

=== Report ===
Model Size:    162.20M

Data Path:            data/fineweb10B
Sequence Length:      1024
Batch Size (global):  128
Batch Size (device):  64
n_layers:              12
n_heads:               6
head_dim:             128
n_embd:               768
Seed:                 0
==============================

Logs for this run will be stored in: runs/02.16/2321_fw_eh_k100.0_lr1e+01_s0/
Writing logs to: runs/02.16/2321_fw_eh_k100.0_lr1e+01_s0/tensorboard_logs
[rank1]: Traceback (most recent call last):
[rank1]:   File "train_gpt2_main.py", line 356, in <module>
[rank1]:     _, loss = model(x_val, y_val, return_logits=False)
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1636, in forward
[rank1]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1454, in _run_ddp_forward
[rank1]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py", line 433, in _fn
[rank1]:     return fn(*args, **kwargs)
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/convert_frame.py", line 1110, in __call__
[rank1]:     return hijacked_callback(
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/convert_frame.py", line 948, in __call__
[rank1]:     result = self._inner_convert(
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/convert_frame.py", line 472, in __call__
[rank1]:     return _compile(
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_utils_internal.py", line 84, in wrapper_function
[rank1]:     return StrobelightCompileTimeProfiler.profile_compile_time(
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_strobelight/compile_time_profiler.py", line 129, in profile_compile_time
[rank1]:     return func(*args, **kwargs)
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/contextlib.py", line 75, in inner
[rank1]:     return func(*args, **kwds)
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/convert_frame.py", line 817, in _compile
[rank1]:     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/utils.py", line 231, in time_wrapper
[rank1]:     r = func(*args, **kwargs)
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/convert_frame.py", line 636, in compile_inner
[rank1]:     out_code = transform_code_object(code, transform)
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/bytecode_transformation.py", line 1185, in transform_code_object
[rank1]:     transformations(instructions, code_options)
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/convert_frame.py", line 178, in _fn
[rank1]:     return fn(*args, **kwargs)
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/convert_frame.py", line 582, in transform
[rank1]:     tracer.run()
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py", line 2451, in run
[rank1]:     super().run()
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py", line 893, in run
[rank1]:     while self.step():
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py", line 805, in step
[rank1]:     self.dispatch_table[inst.opcode](self, inst)
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py", line 2642, in RETURN_VALUE
[rank1]:     self._return(inst)
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py", line 2627, in _return
[rank1]:     self.output.compile_subgraph(
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/output_graph.py", line 1123, in compile_subgraph
[rank1]:     self.compile_and_call_fx_graph(tx, pass2.graph_output_vars(), root)
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/contextlib.py", line 75, in inner
[rank1]:     return func(*args, **kwds)
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/output_graph.py", line 1318, in compile_and_call_fx_graph
[rank1]:     compiled_fn = self.call_user_compiler(gm)
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/utils.py", line 231, in time_wrapper
[rank1]:     r = func(*args, **kwargs)
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/output_graph.py", line 1409, in call_user_compiler
[rank1]:     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/output_graph.py", line 1390, in call_user_compiler
[rank1]:     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/backends/distributed.py", line 626, in compile_fn
[rank1]:     submod_compiler.run(*example_inputs)
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/fx/interpreter.py", line 146, in run
[rank1]:     self.env[node] = self.run_node(node)
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/backends/distributed.py", line 348, in run_node
[rank1]:     compiled_submod_real = self.compile_submod(real_mod, new_args, kwargs)
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/backends/distributed.py", line 263, in compile_submod
[rank1]:     self.compiler(input_mod, args),
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/repro/after_dynamo.py", line 129, in __call__
[rank1]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/__init__.py", line 1951, in __call__
[rank1]:     return compile_fx(model_, inputs_, config_patches=self.config)
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/contextlib.py", line 75, in inner
[rank1]:     return func(*args, **kwds)
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_inductor/compile_fx.py", line 1505, in compile_fx
[rank1]:     return aot_autograd(
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/backends/common.py", line 69, in __call__
[rank1]:     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_functorch/aot_autograd.py", line 954, in aot_module_simplified
[rank1]:     compiled_fn, _ = create_aot_dispatcher_function(
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/utils.py", line 231, in time_wrapper
[rank1]:     r = func(*args, **kwargs)
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_functorch/aot_autograd.py", line 687, in create_aot_dispatcher_function
[rank1]:     compiled_fn, fw_metadata = compiler_fn(
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py", line 290, in aot_dispatch_autograd
[rank1]:     fw_module, bw_module = aot_config.partition_fn(
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_inductor/compile_fx.py", line 1437, in partition_fn
[rank1]:     _recursive_joint_graph_passes(graph)
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_inductor/compile_fx.py", line 256, in _recursive_joint_graph_passes
[rank1]:     joint_graph_passes(gm)
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_inductor/fx_passes/joint_graph.py", line 322, in joint_graph_passes
[rank1]:     constant_fold_uniform_value(graph)
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/contextlib.py", line 75, in inner
[rank1]:     return func(*args, **kwds)
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_inductor/fx_passes/joint_graph.py", line 228, in constant_fold_uniform_value
[rank1]:     cf.run()
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_inductor/constant_folding.py", line 200, in run
[rank1]:     return super().run(initial_env=env)
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/fx/interpreter.py", line 146, in run
[rank1]:     self.env[node] = self.run_node(node)
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_inductor/constant_folding.py", line 162, in run_node
[rank1]:     out = super().run_node(node)
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/fx/interpreter.py", line 203, in run_node
[rank1]:     return getattr(self, n.op)(n.target, args, kwargs)
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/fx/interpreter.py", line 275, in call_function
[rank1]:     return target(*args, **kwargs)
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_ops.py", line 667, in __call__
[rank1]:     return self_._op(*args, **kwargs)
[rank1]: torch._dynamo.exc.BackendCompilerFailed: backend='compile_fn' raised:
[rank1]: OutOfMemoryError: CUDA out of memory. Tried to allocate 193.50 GiB. GPU 1 has a total capacity of 79.11 GiB of which 76.29 GiB is free. Including non-PyTorch memory, this process has 2.81 GiB memory in use. Of the allocated memory 1.26 GiB is allocated by PyTorch, and 27.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[rank1]: While executing %full_1 : [num_users=1] = call_function[target=torch.ops.aten.full.default](args = ([64, 6, 1024, 1024, 129], 0), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:1, pin_memory: False})
[rank1]: Original traceback:
[rank1]:   File "/home/jovyan/fokin/modded-nanogpt/model/model.py", line 228, in forward
[rank1]:     x = block(x)
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/home/jovyan/fokin/modded-nanogpt/model/model.py", line 191, in forward
[rank1]:     x = x + self.attn(F.rms_norm(x, (x.size(-1),)))
[rank1]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/home/jovyan/fokin/modded-nanogpt/model/model.py", line 120, in forward
[rank1]:     dis = distance(lq, lk, k=self.k, dim=-1)
[rank1]:   File "/home/jovyan/fokin/modded-nanogpt/utils/lmath.py", line 108, in distance
[rank1]:     return _dist(x, y, k=k, keepdim=keepdim, dim=dim)
[rank1]:   File "/home/jovyan/fokin/modded-nanogpt/utils/lmath.py", line 113, in _dist
[rank1]:     d = -_inner(x, y, dim=dim, keepdim=keepdim)
[rank1]:   File "/home/jovyan/fokin/modded-nanogpt/utils/lmath.py", line 42, in _inner
[rank1]:     return -uv.narrow(dim, 0, 1).sum(dim=dim, keepdim=False) + uv.narrow(


[rank1]: While executing %submod_1 : [num_users=2] = call_module[target=submod_1](args = (%getitem, %l__self___transformer_h_0_attn_k, %l__self___transformer_h_0_attn_p, %l__self___transformer_h_0_attn_eps, %l__self___transformer_h_0_attn_bias, %getitem_1), kwargs = {})
[rank1]: Original traceback:
[rank1]: None

[rank1]: Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information


[rank1]: You can suppress this exception and fall back to eager by setting:
[rank1]:     import torch._dynamo
[rank1]:     torch._dynamo.config.suppress_errors = True

[rank0]: Traceback (most recent call last):
[rank0]:   File "train_gpt2_main.py", line 356, in <module>
[rank0]:     _, loss = model(x_val, y_val, return_logits=False)
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1636, in forward
[rank0]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1454, in _run_ddp_forward
[rank0]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py", line 433, in _fn
[rank0]:     return fn(*args, **kwargs)
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/convert_frame.py", line 1110, in __call__
[rank0]:     return hijacked_callback(
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/convert_frame.py", line 948, in __call__
[rank0]:     result = self._inner_convert(
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/convert_frame.py", line 472, in __call__
[rank0]:     return _compile(
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_utils_internal.py", line 84, in wrapper_function
[rank0]:     return StrobelightCompileTimeProfiler.profile_compile_time(
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_strobelight/compile_time_profiler.py", line 129, in profile_compile_time
[rank0]:     return func(*args, **kwargs)
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/contextlib.py", line 75, in inner
[rank0]:     return func(*args, **kwds)
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/convert_frame.py", line 817, in _compile
[rank0]:     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/utils.py", line 231, in time_wrapper
[rank0]:     r = func(*args, **kwargs)
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/convert_frame.py", line 636, in compile_inner
[rank0]:     out_code = transform_code_object(code, transform)
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/bytecode_transformation.py", line 1185, in transform_code_object
[rank0]:     transformations(instructions, code_options)
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/convert_frame.py", line 178, in _fn
[rank0]:     return fn(*args, **kwargs)
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/convert_frame.py", line 582, in transform
[rank0]:     tracer.run()
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py", line 2451, in run
[rank0]:     super().run()
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py", line 893, in run
[rank0]:     while self.step():
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py", line 805, in step
[rank0]:     self.dispatch_table[inst.opcode](self, inst)
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py", line 2642, in RETURN_VALUE
[rank0]:     self._return(inst)
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py", line 2627, in _return
[rank0]:     self.output.compile_subgraph(
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/output_graph.py", line 1123, in compile_subgraph
[rank0]:     self.compile_and_call_fx_graph(tx, pass2.graph_output_vars(), root)
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/contextlib.py", line 75, in inner
[rank0]:     return func(*args, **kwds)
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/output_graph.py", line 1318, in compile_and_call_fx_graph
[rank0]:     compiled_fn = self.call_user_compiler(gm)
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/utils.py", line 231, in time_wrapper
[rank0]:     r = func(*args, **kwargs)
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/output_graph.py", line 1409, in call_user_compiler
[rank0]:     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/output_graph.py", line 1390, in call_user_compiler
[rank0]:     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/backends/distributed.py", line 626, in compile_fn
[rank0]:     submod_compiler.run(*example_inputs)
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/fx/interpreter.py", line 146, in run
[rank0]:     self.env[node] = self.run_node(node)
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/backends/distributed.py", line 348, in run_node
[rank0]:     compiled_submod_real = self.compile_submod(real_mod, new_args, kwargs)
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/backends/distributed.py", line 263, in compile_submod
[rank0]:     self.compiler(input_mod, args),
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/repro/after_dynamo.py", line 129, in __call__
[rank0]:     compiled_gm = compiler_fn(gm, example_inputs)
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/__init__.py", line 1951, in __call__
[rank0]:     return compile_fx(model_, inputs_, config_patches=self.config)
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/contextlib.py", line 75, in inner
[rank0]:     return func(*args, **kwds)
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_inductor/compile_fx.py", line 1505, in compile_fx
[rank0]:     return aot_autograd(
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/backends/common.py", line 69, in __call__
[rank0]:     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_functorch/aot_autograd.py", line 954, in aot_module_simplified
[rank0]:     compiled_fn, _ = create_aot_dispatcher_function(
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_dynamo/utils.py", line 231, in time_wrapper
[rank0]:     r = func(*args, **kwargs)
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_functorch/aot_autograd.py", line 687, in create_aot_dispatcher_function
[rank0]:     compiled_fn, fw_metadata = compiler_fn(
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py", line 290, in aot_dispatch_autograd
[rank0]:     fw_module, bw_module = aot_config.partition_fn(
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_inductor/compile_fx.py", line 1437, in partition_fn
[rank0]:     _recursive_joint_graph_passes(graph)
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_inductor/compile_fx.py", line 256, in _recursive_joint_graph_passes
[rank0]:     joint_graph_passes(gm)
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_inductor/fx_passes/joint_graph.py", line 322, in joint_graph_passes
[rank0]:     constant_fold_uniform_value(graph)
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/contextlib.py", line 75, in inner
[rank0]:     return func(*args, **kwds)
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_inductor/fx_passes/joint_graph.py", line 228, in constant_fold_uniform_value
[rank0]:     cf.run()
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_inductor/constant_folding.py", line 200, in run
[rank0]:     return super().run(initial_env=env)
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/fx/interpreter.py", line 146, in run
[rank0]:     self.env[node] = self.run_node(node)
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_inductor/constant_folding.py", line 162, in run_node
[rank0]:     out = super().run_node(node)
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/fx/interpreter.py", line 203, in run_node
[rank0]:     return getattr(self, n.op)(n.target, args, kwargs)
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/fx/interpreter.py", line 275, in call_function
[rank0]:     return target(*args, **kwargs)
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/_ops.py", line 667, in __call__
[rank0]:     return self_._op(*args, **kwargs)
[rank0]: torch._dynamo.exc.BackendCompilerFailed: backend='compile_fn' raised:
[rank0]: OutOfMemoryError: CUDA out of memory. Tried to allocate 193.50 GiB. GPU 0 has a total capacity of 79.11 GiB of which 76.29 GiB is free. Including non-PyTorch memory, this process has 2.81 GiB memory in use. Of the allocated memory 1.26 GiB is allocated by PyTorch, and 27.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[rank0]: While executing %full_1 : [num_users=1] = call_function[target=torch.ops.aten.full.default](args = ([64, 6, 1024, 1024, 129], 0), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
[rank0]: Original traceback:
[rank0]:   File "/home/jovyan/fokin/modded-nanogpt/model/model.py", line 228, in forward
[rank0]:     x = block(x)
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/jovyan/fokin/modded-nanogpt/model/model.py", line 191, in forward
[rank0]:     x = x + self.attn(F.rms_norm(x, (x.size(-1),)))
[rank0]:   File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/jovyan/fokin/modded-nanogpt/model/model.py", line 120, in forward
[rank0]:     dis = distance(lq, lk, k=self.k, dim=-1)
[rank0]:   File "/home/jovyan/fokin/modded-nanogpt/utils/lmath.py", line 108, in distance
[rank0]:     return _dist(x, y, k=k, keepdim=keepdim, dim=dim)
[rank0]:   File "/home/jovyan/fokin/modded-nanogpt/utils/lmath.py", line 113, in _dist
[rank0]:     d = -_inner(x, y, dim=dim, keepdim=keepdim)
[rank0]:   File "/home/jovyan/fokin/modded-nanogpt/utils/lmath.py", line 42, in _inner
[rank0]:     return -uv.narrow(dim, 0, 1).sum(dim=dim, keepdim=False) + uv.narrow(


[rank0]: While executing %submod_1 : [num_users=2] = call_module[target=submod_1](args = (%getitem, %l__self___transformer_h_0_attn_k, %l__self___transformer_h_0_attn_p, %l__self___transformer_h_0_attn_eps, %l__self___transformer_h_0_attn_bias, %getitem_1), kwargs = {})
[rank0]: Original traceback:
[rank0]: None

[rank0]: Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information


[rank0]: You can suppress this exception and fall back to eager by setting:
[rank0]:     import torch._dynamo
[rank0]:     torch._dynamo.config.suppress_errors = True

W0216 00:38:47.353698 140466949732160 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 1240655 closing signal SIGTERM
E0216 00:38:47.769656 140466949732160 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 1 (pid: 1240656) of binary: /home/jovyan/miniconda3/envs/fokin_HCNN/bin/python
Traceback (most recent call last):
  File "/home/jovyan/miniconda3/envs/fokin_HCNN/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 348, in wrapper
    return f(*args, **kwargs)
  File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/distributed/run.py", line 901, in main
    run(args)
  File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/jovyan/miniconda3/envs/fokin_HCNN/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train_gpt2_main.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-02-16_00:38:47
  host      : hopper-h100-0
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 1240656)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
