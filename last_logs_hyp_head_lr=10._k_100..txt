W0126 18:07:01.620877 140575190263616 torch/distributed/run.py:779] 
W0126 18:07:01.620877 140575190263616 torch/distributed/run.py:779] *****************************************
W0126 18:07:01.620877 140575190263616 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0126 18:07:01.620877 140575190263616 torch/distributed/run.py:779] *****************************************
[Rank 0] Using device: cuda:0
[Rank 0] This is the master process.
[Rank 0] Training DataLoader: 2700000000 tokens across 27 files.
[Rank 0] Validation DataLoader: 100000000 tokens across 1 files.
[Rank 1] Using device: cuda:1
[Rank 0] Model wrapped in DDP.
k params lengths: head = 1, attn = 0
head.k is learned with 10.0 lr

=== Minimal Report ===
Model Size:    162.20M parameters

=== Relevant Hyperparameters ===
Data Path:            /home/jovyan/fokin/modded-nanogpt/data/fineweb10B
Sequence Length:      1024
Batch Size (global):  64
Batch Size (device):  32
n_layer:              12
n_head:               6
head_dim:             128
n_embd:               768
Seed:                 0
==============================

Logs for this run will be stored in: runs/26.01_65236_k_100.0_lr_10.0_0/
Writing logs to: runs/26.01_65236_k_100.0_lr_10.0_0/tensorboard_logs
step:0/30, tokens seen: 0.00M, val_loss:11.0006 train_time:0.23s step_avg:nanms
Head curvature value: 100.29
step:10/30, tokens seen:0.59M, avg_train_loss:8.7658 time:70/nans step_avg:nanms
step:10/30, tokens seen: 0.66M, val_loss:7.9480 train_time:0.00s step_avg:nanms
Head curvature value: 100.58
step:20/30, tokens seen:1.25M, avg_train_loss:7.6095 time:77/4s step_avg:132ms
step:20/30, tokens seen: 1.31M, val_loss:7.4307 train_time:1.32s step_avg:132ms
Head curvature value: 100.78
step:30/30, tokens seen:1.90M, avg_train_loss:7.2571 time:83/4s step_avg:132ms
step:30/30, tokens seen: 1.97M, val_loss:7.2449 train_time:2.63s step_avg:132ms
Total training time: 90.49s
peak memory consumption: 57976 MiB
